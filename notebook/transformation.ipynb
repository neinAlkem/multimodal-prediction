{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6bd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame, types\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6516ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/Bagas/spark/spark-3.5.5-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/Bagas/.ivy2/cache\n",
      "The jars for the packages stored in: /home/Bagas/.ivy2/jars\n",
      "ai.catboost#catboost-spark_3.5_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9209b7a2-5fe1-43fc-b42e-303826b5ef3f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound ai.catboost#catboost-spark_3.5_2.12;1.2.6 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.6.0 in central\n",
      "\tfound com.google.guava#guava;32.0.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;3.33.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;2.8 in central\n",
      "\tfound commons-io#commons-io;2.7 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.11 in central\n",
      "\tfound org.apache.commons#commons-text;1.10.0 in central\n",
      "\tfound org.json4s#json4s-jackson_2.12;3.7.0-M11 in central\n",
      "\tfound org.json4s#json4s-core_2.12;3.7.0-M11 in central\n",
      "\tfound org.json4s#json4s-ast_2.12;3.7.0-M11 in central\n",
      "\tfound org.json4s#json4s-scalap_2.12;3.7.0-M11 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.module#jackson-module-scala_2.12;2.15.2 in central\n",
      "\tfound io.github.classgraph#classgraph;4.8.98 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.1 in central\n",
      "\tfound ai.catboost#catboost-common;1.2.6 in central\n",
      "\tfound javax.validation#validation-api;1.1.0.Final in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.25 in central\n",
      "\tfound ai.catboost#catboost-spark-macros_2.12;1.2.6 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.12 in central\n",
      ":: resolution report :: resolve 675ms :: artifacts dl 40ms\n",
      "\t:: modules in use:\n",
      "\tai.catboost#catboost-common;1.2.6 from central in [default]\n",
      "\tai.catboost#catboost-spark-macros_2.12;1.2.6 from central in [default]\n",
      "\tai.catboost#catboost-spark_3.5_2.12;1.2.6 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.module#jackson-module-scala_2.12;2.15.2 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;32.0.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;2.8 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcommons-io#commons-io;2.7 from central in [default]\n",
      "\tio.github.classgraph#classgraph;4.8.98 from central in [default]\n",
      "\tjavax.validation#validation-api;1.1.0.Final from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.11 from central in [default]\n",
      "\torg.apache.commons#commons-text;1.10.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.33.0 from central in [default]\n",
      "\torg.json4s#json4s-ast_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.json4s#json4s-core_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.json4s#json4s-jackson_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.json4s#json4s-scalap_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.12 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.6.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.25 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.commons#commons-lang3;3.12.0 by [org.apache.commons#commons-lang3;3.11] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.12.2 by [com.fasterxml.jackson.core#jackson-databind;2.15.2] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   30  |   0   |   0   |   2   ||   28  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9209b7a2-5fe1-43fc-b42e-303826b5ef3f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 28 already retrieved (0kB/12ms)\n",
      "25/06/04 09:07:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('spark://localhost:7077') \\\n",
    "    .config(\"spark.jars\", \"https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop3-latest.jar\") \\\n",
    "    .config(\"spark.jars.packages\", \"ai.catboost:catboost-spark_3.5_2.12:1.2.6\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"false\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.type\", \"SERVICE_ACCOUNT_JSON_KEYFILE\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.project.id\", os.getenv('PROJECT_ID')) \\\n",
    "    .appName(\"transformation_spark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34900d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://abd-vm.us-central1-c.c.project-big-data-461104.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://localhost:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>transformation_spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7cd4c5696e40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b398a962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "base_dir = \"gs://project-abd/notebook-data/\"\n",
    "\n",
    "try:\n",
    "    df = spark.read.csv(os.path.join(base_dir,'fusion_data.csv'),\n",
    "                        header=True,\n",
    "                        inferSchema=True)\n",
    "except Exception as e:\n",
    "    print(f'Error while reading data : {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33372b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+-----------+---+-------------------+-----------------+------------------+-------------------+------------------+--------------------+----------------+\n",
      "|class_id|room|student_id|gender_code|age|          timestamp|          hr_mean|         temp_mean|           eda_mean|          ibi_mean|            bvp_mean|engagement_level|\n",
      "+--------+----+----------+-----------+---+-------------------+-----------------+------------------+-------------------+------------------+--------------------+----------------+\n",
      "|       7|  R3|        21|          1| 15|2025-06-04 10:55:00|96.89173352559408|29.075799973805747| 0.2409935087157646|0.7601556011424158| 0.14733649224615267|  Highly Engaged|\n",
      "|     202|  R1|        20|          1| 16|2025-06-04 14:15:00|84.53866225022536|   32.529366131322|0.15323040743138613|0.7591810502657076|0.024287718439838422|  Highly Engaged|\n",
      "|      78|  R3|         1|          1| 16|2025-06-04 11:25:00|71.10822733748319| 32.39248572278758|0.16132125217433368|0.8025367164611816|-0.03438250654092...|     Not Engaged|\n",
      "|     107|  R2|         7|          1| 15|2025-06-04 10:50:00|83.33713343302409|27.814800027211508|0.16911867160350083|0.7535067664252387|0.004243224004070...|     Not Engaged|\n",
      "|     161|  R1|        10|          1| 15|2025-06-04 13:20:00|92.01420000712076|32.538799896240235|  0.343952368820707|0.7671844915645879|0.013165624121029396|     Not Engaged|\n",
      "+--------+----+----------+-----------+---+-------------------+-----------------+------------------+-------------------+------------------+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68ebc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 09:07:31 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+----+------------------+-----------+------------------+------------------+------------------+------------------+-------------------+--------------------+----------------+\n",
      "|summary|         class_id|room|        student_id|gender_code|               age|           hr_mean|         temp_mean|          eda_mean|           ibi_mean|            bvp_mean|engagement_level|\n",
      "+-------+-----------------+----+------------------+-----------+------------------+------------------+------------------+------------------+-------------------+--------------------+----------------+\n",
      "|  count|              248| 248|               248|        248|               248|               248|               248|               248|                248|                 248|             248|\n",
      "|   mean|132.1048387096774|NULL|13.060483870967742|        1.0|            15.875| 87.06891107648762|31.650660187285208|0.9649842082417228| 0.7606887402130599|0.003096441220778...|            NULL|\n",
      "| stddev|69.63860655592414|NULL|  7.04700606653372|        0.0|0.4178458348486976|12.319919595245377|2.6830722529034348|2.0504901418918378|0.12113546540991996| 0.15163258533219537|            NULL|\n",
      "|    min|                5|  R1|                 1|          1|                15|   65.880199953715|  22.4360217554953|               0.0|0.37501699649370634|-0.47395779518876224|         Engaged|\n",
      "|    max|              241|  R5|                23|          1|                17|144.85186596770785|36.128733469645184|21.521650007309965|  1.046923041343689|  0.6698338952293852|     Not Engaged|\n",
      "+-------+-----------------+----+------------------+-----------+------------------+------------------+------------------+------------------+-------------------+--------------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b86d632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indexers = [StringIndexer(inputCol=\"room\", outputCol=\"room_index\") , StringIndexer(inputCol=\"engagement_level\", outputCol=\"label_index\")]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a21ea8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+-----------+---+-------------------+-----------------+------------------+-------------------+------------------+--------------------+----------------+----------+-----------+\n",
      "|class_id|room|student_id|gender_code|age|          timestamp|          hr_mean|         temp_mean|           eda_mean|          ibi_mean|            bvp_mean|engagement_level|room_index|label_index|\n",
      "+--------+----+----------+-----------+---+-------------------+-----------------+------------------+-------------------+------------------+--------------------+----------------+----------+-----------+\n",
      "|       7|  R3|        21|          1| 15|2025-06-04 10:55:00|96.89173352559408|29.075799973805747| 0.2409935087157646|0.7601556011424158| 0.14733649224615267|  Highly Engaged|       1.0|        0.0|\n",
      "|     202|  R1|        20|          1| 16|2025-06-04 14:15:00|84.53866225022536|   32.529366131322|0.15323040743138613|0.7591810502657076|0.024287718439838422|  Highly Engaged|       0.0|        0.0|\n",
      "|      78|  R3|         1|          1| 16|2025-06-04 11:25:00|71.10822733748319| 32.39248572278758|0.16132125217433368|0.8025367164611816|-0.03438250654092...|     Not Engaged|       1.0|        1.0|\n",
      "|     107|  R2|         7|          1| 15|2025-06-04 10:50:00|83.33713343302409|27.814800027211508|0.16911867160350083|0.7535067664252387|0.004243224004070...|     Not Engaged|       3.0|        1.0|\n",
      "|     161|  R1|        10|          1| 15|2025-06-04 13:20:00|92.01420000712076|32.538799896240235|  0.343952368820707|0.7671844915645879|0.013165624121029396|     Not Engaged|       0.0|        1.0|\n",
      "+--------+----+----------+-----------+---+-------------------+-----------------+------------------+-------------------+------------------+--------------------+----------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158dd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['room_index','gender_code','age','hr_mean','temp_mean','eda_mean','ibi_mean','bvp_mean']\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "df_prep = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb84582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+-----------+---+-------------------+-----------------+------------------+-------------------+------------------+--------------------+----------------+----------+-----------+--------------------+\n",
      "|class_id|room|student_id|gender_code|age|          timestamp|          hr_mean|         temp_mean|           eda_mean|          ibi_mean|            bvp_mean|engagement_level|room_index|label_index|            features|\n",
      "+--------+----+----------+-----------+---+-------------------+-----------------+------------------+-------------------+------------------+--------------------+----------------+----------+-----------+--------------------+\n",
      "|       7|  R3|        21|          1| 15|2025-06-04 10:55:00|96.89173352559408|29.075799973805747| 0.2409935087157646|0.7601556011424158| 0.14733649224615267|  Highly Engaged|       1.0|        0.0|[1.0,1.0,15.0,96....|\n",
      "|     202|  R1|        20|          1| 16|2025-06-04 14:15:00|84.53866225022536|   32.529366131322|0.15323040743138613|0.7591810502657076|0.024287718439838422|  Highly Engaged|       0.0|        0.0|[0.0,1.0,16.0,84....|\n",
      "|      78|  R3|         1|          1| 16|2025-06-04 11:25:00|71.10822733748319| 32.39248572278758|0.16132125217433368|0.8025367164611816|-0.03438250654092...|     Not Engaged|       1.0|        1.0|[1.0,1.0,16.0,71....|\n",
      "|     107|  R2|         7|          1| 15|2025-06-04 10:50:00|83.33713343302409|27.814800027211508|0.16911867160350083|0.7535067664252387|0.004243224004070...|     Not Engaged|       3.0|        1.0|[3.0,1.0,15.0,83....|\n",
      "|     161|  R1|        10|          1| 15|2025-06-04 13:20:00|92.01420000712076|32.538799896240235|  0.343952368820707|0.7671844915645879|0.013165624121029396|     Not Engaged|       0.0|        1.0|[0.0,1.0,15.0,92....|\n",
      "+--------+----+----------+-----------+---+-------------------+-----------------+------------------+-------------------+------------------+--------------------+----------------+----------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_prep.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a413485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df_prep.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25eef86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b172934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c435257",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='label_index', \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58e9cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost_spark\n",
    "from catboost_spark import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2e78508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pool_f609cdb1e18d"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pool = catboost_spark.Pool(train_df.select(['features', 'label_index']))\n",
    "train_pool.setLabelCol('label_index')\n",
    "train_pool.setFeaturesCol('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ae44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = catboost_spark.CatBoostClassifier(featuresCol='features', labelCol='label_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7b3e837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatBoostClassifier_ed8add82c51b"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.setIterations(1000)\n",
    "classifier.setDepth(10)\n",
    "classifier.setLearningRate(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e67e2aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 09:08:03 WARN TaskSetManager: Lost task 0.0 in stage 22.0 (TID 22) (172.18.0.6 executor 1): java.lang.ClassCastException: cannot assign instance of java.lang.invoke.SerializedLambda to field org.apache.spark.sql.execution.MapPartitionsExec.func of type scala.Function1 in instance of org.apache.spark.sql.execution.MapPartitionsExec\n",
      "\tat java.base/java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2076)\n",
      "\tat java.base/java.io.ObjectStreamClass$FieldReflector.checkObjectFieldValueTypes(ObjectStreamClass.java:2039)\n",
      "\tat java.base/java.io.ObjectStreamClass.checkObjFieldValueTypes(ObjectStreamClass.java:1293)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultCheckFieldValues(ObjectInputStream.java:2512)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2419)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n",
      "\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:2134)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1675)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n",
      "\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:2134)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1675)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n",
      "\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n",
      "\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:129)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "25/06/04 09:08:03 ERROR TaskSetManager: Task 0 in stage 22.0 failed 4 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o184.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 22.0 failed 4 times, most recent failure: Lost task 0.3 in stage 22.0 (TID 25) (172.18.0.5 executor 2): java.lang.ClassCastException: cannot assign instance of java.lang.invoke.SerializedLambda to field org.apache.spark.sql.execution.MapPartitionsExec.func of type scala.Function1 in instance of org.apache.spark.sql.execution.MapPartitionsExec\n\tat java.base/java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2076)\n\tat java.base/java.io.ObjectStreamClass$FieldReflector.checkObjectFieldValueTypes(ObjectStreamClass.java:2039)\n\tat java.base/java.io.ObjectStreamClass.checkObjFieldValueTypes(ObjectStreamClass.java:1293)\n\tat java.base/java.io.ObjectInputStream.defaultCheckFieldValues(ObjectInputStream.java:2512)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2419)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:2134)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1675)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:2134)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1675)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)\n\tat jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)\n\tat jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)\n\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:129)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:90)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n\tat org.apache.spark.rdd.RDD.collectPartition$1(RDD.scala:1064)\n\tat org.apache.spark.rdd.RDD.$anonfun$toLocalIterator$3(RDD.scala:1066)\n\tat org.apache.spark.rdd.RDD.$anonfun$toLocalIterator$3$adapted(RDD.scala:1066)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator.toStream(Iterator.scala:1417)\n\tat scala.collection.Iterator.toStream$(Iterator.scala:1416)\n\tat scala.collection.AbstractIterator.toStream(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.toSeq(TraversableOnce.scala:354)\n\tat scala.collection.TraversableOnce.toSeq$(TraversableOnce.scala:354)\n\tat scala.collection.AbstractIterator.toSeq(Iterator.scala:1431)\n\tat ai.catboost.spark.DataHelpers$.getDistinctFloatLabelValues(DataHelpers.scala:815)\n\tat ai.catboost.spark.CatBoostClassifier.preprocessBeforeTraining(CatBoostClassifier.scala:399)\n\tat ai.catboost.spark.CatBoostPredictorTrait.fit(CatBoostPredictor.scala:167)\n\tat ai.catboost.spark.CatBoostPredictorTrait.fit$(CatBoostPredictor.scala:125)\n\tat ai.catboost.spark.CatBoostClassifier.fit(CatBoostClassifier.scala:372)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: java.lang.ClassCastException: cannot assign instance of java.lang.invoke.SerializedLambda to field org.apache.spark.sql.execution.MapPartitionsExec.func of type scala.Function1 in instance of org.apache.spark.sql.execution.MapPartitionsExec\n\tat java.base/java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2076)\n\tat java.base/java.io.ObjectStreamClass$FieldReflector.checkObjectFieldValueTypes(ObjectStreamClass.java:2039)\n\tat java.base/java.io.ObjectStreamClass.checkObjFieldValueTypes(ObjectStreamClass.java:1293)\n\tat java.base/java.io.ObjectInputStream.defaultCheckFieldValues(ObjectInputStream.java:2512)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2419)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:2134)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1675)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:2134)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1675)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)\n\tat jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)\n\tat jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)\n\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:129)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:90)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m predict = model.transform(test_df)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mModel F1 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluator.evaluate(predict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/spark-d3138fe7-85fd-4fa4-af7d-8a31e46e1d3a/userFiles-a4a3d567-baf7-48ba-a239-8534f51b8af8/ai.catboost_catboost-spark_3.5_2.12-1.2.6.jar/catboost_spark/core.py:5362\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, dataset, params, evalDatasets)\u001b[39m\n\u001b[32m   5359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_with_eval(trainDatasetAsJavaObject, evalDatasetsAsJavaObject, params)\n\u001b[32m   5361\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(params, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m5362\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fit_with_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5363\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(params, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m   5364\u001b[39m     models = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/spark-d3138fe7-85fd-4fa4-af7d-8a31e46e1d3a/userFiles-a4a3d567-baf7-48ba-a239-8534f51b8af8/ai.catboost_catboost-spark_3.5_2.12-1.2.6.jar/catboost_spark/core.py:5359\u001b[39m, in \u001b[36mCatBoostClassifier.fit.<locals>._fit_with_eval\u001b[39m\u001b[34m(params)\u001b[39m\n\u001b[32m   5358\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fit_with_eval\u001b[39m(params):\n\u001b[32m-> \u001b[39m\u001b[32m5359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_with_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainDatasetAsJavaObject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalDatasetsAsJavaObject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/spark-d3138fe7-85fd-4fa4-af7d-8a31e46e1d3a/userFiles-a4a3d567-baf7-48ba-a239-8534f51b8af8/ai.catboost_catboost-spark_3.5_2.12-1.2.6.jar/catboost_spark/core.py:5316\u001b[39m, in \u001b[36mCatBoostClassifier._fit_with_eval\u001b[39m\u001b[34m(self, trainDatasetAsJavaObject, evalDatasetsAsJavaObject, params)\u001b[39m\n\u001b[32m   5314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5315\u001b[39m     \u001b[38;5;28mself\u001b[39m._transfer_params_to_java()\n\u001b[32m-> \u001b[39m\u001b[32m5316\u001b[39m     java_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_java_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainDatasetAsJavaObject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalDatasetsAsJavaObject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m CatBoostClassificationModel(java_model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o184.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 22.0 failed 4 times, most recent failure: Lost task 0.3 in stage 22.0 (TID 25) (172.18.0.5 executor 2): java.lang.ClassCastException: cannot assign instance of java.lang.invoke.SerializedLambda to field org.apache.spark.sql.execution.MapPartitionsExec.func of type scala.Function1 in instance of org.apache.spark.sql.execution.MapPartitionsExec\n\tat java.base/java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2076)\n\tat java.base/java.io.ObjectStreamClass$FieldReflector.checkObjectFieldValueTypes(ObjectStreamClass.java:2039)\n\tat java.base/java.io.ObjectStreamClass.checkObjFieldValueTypes(ObjectStreamClass.java:1293)\n\tat java.base/java.io.ObjectInputStream.defaultCheckFieldValues(ObjectInputStream.java:2512)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2419)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:2134)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1675)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:2134)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1675)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)\n\tat jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)\n\tat jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)\n\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:129)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:90)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n\tat org.apache.spark.rdd.RDD.collectPartition$1(RDD.scala:1064)\n\tat org.apache.spark.rdd.RDD.$anonfun$toLocalIterator$3(RDD.scala:1066)\n\tat org.apache.spark.rdd.RDD.$anonfun$toLocalIterator$3$adapted(RDD.scala:1066)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator.toStream(Iterator.scala:1417)\n\tat scala.collection.Iterator.toStream$(Iterator.scala:1416)\n\tat scala.collection.AbstractIterator.toStream(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.toSeq(TraversableOnce.scala:354)\n\tat scala.collection.TraversableOnce.toSeq$(TraversableOnce.scala:354)\n\tat scala.collection.AbstractIterator.toSeq(Iterator.scala:1431)\n\tat ai.catboost.spark.DataHelpers$.getDistinctFloatLabelValues(DataHelpers.scala:815)\n\tat ai.catboost.spark.CatBoostClassifier.preprocessBeforeTraining(CatBoostClassifier.scala:399)\n\tat ai.catboost.spark.CatBoostPredictorTrait.fit(CatBoostPredictor.scala:167)\n\tat ai.catboost.spark.CatBoostPredictorTrait.fit$(CatBoostPredictor.scala:125)\n\tat ai.catboost.spark.CatBoostClassifier.fit(CatBoostClassifier.scala:372)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: java.lang.ClassCastException: cannot assign instance of java.lang.invoke.SerializedLambda to field org.apache.spark.sql.execution.MapPartitionsExec.func of type scala.Function1 in instance of org.apache.spark.sql.execution.MapPartitionsExec\n\tat java.base/java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2076)\n\tat java.base/java.io.ObjectStreamClass$FieldReflector.checkObjectFieldValueTypes(ObjectStreamClass.java:2039)\n\tat java.base/java.io.ObjectStreamClass.checkObjFieldValueTypes(ObjectStreamClass.java:1293)\n\tat java.base/java.io.ObjectInputStream.defaultCheckFieldValues(ObjectInputStream.java:2512)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2419)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:2134)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1675)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:2134)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1675)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)\n\tat jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)\n\tat jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)\n\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)\n\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)\n\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:129)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:90)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "model = classifier.fit(train_pool)\n",
    "predict = model.transform(test_df)\n",
    "print(f'Model F1 = {evaluator.evaluate(predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba133212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 08:59:04 WARN CacheManager: Asked to cache already cached data.\n",
      "25/06/04 08:59:04 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 08:59:07 ERROR Executor: Exception in task 0.0 in stage 56921.0 (TID 33870)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:07 WARN TaskSetManager: Lost task 0.0 in stage 56921.0 (TID 33870) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:07 ERROR TaskSetManager: Task 0 in stage 56921.0 failed 1 times; aborting job\n",
      "25/06/04 08:59:14 ERROR Executor: Exception in task 0.0 in stage 57857.0 (TID 34379)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:14 WARN TaskSetManager: Lost task 0.0 in stage 57857.0 (TID 34379) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:14 ERROR TaskSetManager: Task 0 in stage 57857.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tlearn: 0.8481283\ttotal: 4m 11s\tremaining: 5m 42s\n",
      "847:\tlearn: 0.8478723\ttotal: 4m 12s\tremaining: 5m 42s\n",
      "848:\tlearn: 0.8477398\ttotal: 4m 12s\tremaining: 5m 42s\n",
      "849:\tlearn: 0.8474459\ttotal: 4m 12s\tremaining: 5m 42s\n",
      "850:\tlearn: 0.8471360\ttotal: 4m 13s\tremaining: 5m 41s\n",
      "851:\tlearn: 0.8469288\ttotal: 4m 13s\tremaining: 5m 41s\n",
      "852:\tlearn: 0.8466051\ttotal: 4m 14s\tremaining: 5m 41s\n",
      "853:\tlearn: 0.8463092\ttotal: 4m 14s\tremaining: 5m 41s\n",
      "854:\tlearn: 0.8461194\ttotal: 4m 14s\tremaining: 5m 41s\n",
      "855:\tlearn: 0.8457546\ttotal: 4m 15s\tremaining: 5m 41s\n",
      "856:\tlearn: 0.8455120\ttotal: 4m 15s\tremaining: 5m 41s\n",
      "857:\tlearn: 0.8452289\ttotal: 4m 16s\tremaining: 5m 41s\n",
      "858:\tlearn: 0.8450670\ttotal: 4m 16s\tremaining: 5m 40s\n",
      "859:\tlearn: 0.8449134\ttotal: 4m 16s\tremaining: 5m 40s\n",
      "860:\tlearn: 0.8446342\ttotal: 4m 17s\tremaining: 5m 40s\n",
      "861:\tlearn: 0.8443739\ttotal: 4m 17s\tremaining: 5m 40s\n",
      "862:\tlearn: 0.8441379\ttotal: 4m 17s\tremaining: 5m 39s\n",
      "863:\tlearn: 0.8440175\ttotal: 4m 18s\tremaining: 5m 39s\n",
      "864:\tlearn: 0.8437892\ttotal: 4m 18s\tremaining: 5m 39s\n",
      "865:\tlearn: 0.8434792\ttotal: 4m 18s\tremaining: 5m 39s\n",
      "866:\tlearn: 0.8432000\ttotal: 4m 19s\tremaining: 5m 39s\n",
      "867:\tlearn: 0.8430638\ttotal: 4m 19s\tremaining: 5m 38s\n",
      "868:\tlearn: 0.8429257\ttotal: 4m 19s\tremaining: 5m 38s\n",
      "869:\tlearn: 0.8426915\ttotal: 4m 20s\tremaining: 5m 38s\n",
      "870:\tlearn: 0.8424030\ttotal: 4m 21s\tremaining: 5m 38s\n",
      "871:\tlearn: 0.8422287\ttotal: 4m 21s\tremaining: 5m 38s\n",
      "872:\tlearn: 0.8420711\ttotal: 4m 21s\tremaining: 5m 37s\n",
      "873:\tlearn: 0.8417860\ttotal: 4m 22s\tremaining: 5m 37s\n",
      "874:\tlearn: 0.8415658\ttotal: 4m 22s\tremaining: 5m 37s\n",
      "875:\tlearn: 0.8413073\ttotal: 4m 23s\tremaining: 5m 37s\n",
      "876:\tlearn: 0.8409994\ttotal: 4m 23s\tremaining: 5m 37s\n",
      "877:\tlearn: 0.8406866\ttotal: 4m 23s\tremaining: 5m 37s\n",
      "878:\tlearn: 0.8405802\ttotal: 4m 24s\tremaining: 5m 36s\n",
      "879:\tlearn: 0.8403231\ttotal: 4m 24s\tremaining: 5m 36s\n",
      "880:\tlearn: 0.8402097\ttotal: 4m 24s\tremaining: 5m 36s\n",
      "881:\tlearn: 0.8401040\ttotal: 4m 25s\tremaining: 5m 35s\n",
      "882:\tlearn: 0.8397780\ttotal: 4m 25s\tremaining: 5m 35s\n",
      "883:\tlearn: 0.8396391\ttotal: 4m 25s\tremaining: 5m 35s\n",
      "884:\tlearn: 0.8394244\ttotal: 4m 26s\tremaining: 5m 35s\n",
      "885:\tlearn: 0.8393280\ttotal: 4m 26s\tremaining: 5m 34s\n",
      "886:\tlearn: 0.8390846\ttotal: 4m 26s\tremaining: 5m 34s\n",
      "887:\tlearn: 0.8388063\ttotal: 4m 27s\tremaining: 5m 34s\n",
      "888:\tlearn: 0.8386547\ttotal: 4m 27s\tremaining: 5m 34s\n",
      "889:\tlearn: 0.8383703\ttotal: 4m 27s\tremaining: 5m 34s\n",
      "890:\tlearn: 0.8381688\ttotal: 4m 28s\tremaining: 5m 34s\n",
      "891:\tlearn: 0.8378700\ttotal: 4m 28s\tremaining: 5m 33s\n",
      "892:\tlearn: 0.8376312\ttotal: 4m 29s\tremaining: 5m 33s\n",
      "893:\tlearn: 0.8373139\ttotal: 4m 29s\tremaining: 5m 33s\n",
      "894:\tlearn: 0.8369950\ttotal: 4m 30s\tremaining: 5m 33s\n",
      "895:\tlearn: 0.8366711\ttotal: 4m 30s\tremaining: 5m 33s\n",
      "896:\tlearn: 0.8364201\ttotal: 4m 30s\tremaining: 5m 33s\n",
      "897:\tlearn: 0.8362480\ttotal: 4m 31s\tremaining: 5m 32s\n",
      "898:\tlearn: 0.8359381\ttotal: 4m 31s\tremaining: 5m 32s\n",
      "899:\tlearn: 0.8358214\ttotal: 4m 31s\tremaining: 5m 32s\n",
      "900:\tlearn: 0.8356957\ttotal: 4m 31s\tremaining: 5m 31s\n",
      "901:\tlearn: 0.8354837\ttotal: 4m 32s\tremaining: 5m 31s\n",
      "902:\tlearn: 0.8352699\ttotal: 4m 32s\tremaining: 5m 31s\n",
      "903:\tlearn: 0.8350631\ttotal: 4m 32s\tremaining: 5m 30s\n",
      "904:\tlearn: 0.8349877\ttotal: 4m 33s\tremaining: 5m 30s\n",
      "905:\tlearn: 0.8348371\ttotal: 4m 33s\tremaining: 5m 30s\n",
      "906:\tlearn: 0.8345482\ttotal: 4m 33s\tremaining: 5m 29s\n",
      "907:\tlearn: 0.8344107\ttotal: 4m 33s\tremaining: 5m 29s\n",
      "908:\tlearn: 0.8340805\ttotal: 4m 34s\tremaining: 5m 29s\n",
      "909:\tlearn: 0.8337853\ttotal: 4m 34s\tremaining: 5m 29s\n",
      "910:\tlearn: 0.8334885\ttotal: 4m 35s\tremaining: 5m 29s\n",
      "911:\tlearn: 0.8332242\ttotal: 4m 35s\tremaining: 5m 28s\n",
      "912:\tlearn: 0.8329785\ttotal: 4m 36s\tremaining: 5m 28s\n",
      "913:\tlearn: 0.8327504\ttotal: 4m 36s\tremaining: 5m 28s\n",
      "914:\tlearn: 0.8324674\ttotal: 4m 37s\tremaining: 5m 28s\n",
      "915:\tlearn: 0.8322693\ttotal: 4m 37s\tremaining: 5m 28s\n",
      "916:\tlearn: 0.8321712\ttotal: 4m 37s\tremaining: 5m 27s\n",
      "917:\tlearn: 0.8319144\ttotal: 4m 38s\tremaining: 5m 27s\n",
      "918:\tlearn: 0.8316289\ttotal: 4m 38s\tremaining: 5m 27s\n",
      "919:\tlearn: 0.8313746\ttotal: 4m 39s\tremaining: 5m 27s\n",
      "920:\tlearn: 0.8310946\ttotal: 4m 39s\tremaining: 5m 27s\n",
      "921:\tlearn: 0.8308655\ttotal: 4m 39s\tremaining: 5m "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 08:59:21 ERROR Executor: Exception in task 0.0 in stage 58662.0 (TID 34841)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:21 WARN TaskSetManager: Lost task 0.0 in stage 58662.0 (TID 34841) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:21 ERROR TaskSetManager: Task 0 in stage 58662.0 failed 1 times; aborting job\n",
      "25/06/04 08:59:22 ERROR Executor: Exception in task 0.0 in stage 58770.0 (TID 34915)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:22 WARN TaskSetManager: Lost task 0.0 in stage 58770.0 (TID 34915) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:22 ERROR TaskSetManager: Task 0 in stage 58770.0 failed 1 times; aborting job\n",
      "25/06/04 08:59:27 ERROR Executor: Exception in task 0.0 in stage 59173.0 (TID 35160)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:27 WARN TaskSetManager: Lost task 0.0 in stage 59173.0 (TID 35160) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:27 ERROR TaskSetManager: Task 0 in stage 59173.0 failed 1 times; aborting job\n",
      "25/06/04 08:59:30 ERROR Executor: Exception in task 0.0 in stage 59435.0 (TID 35332)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:30 WARN TaskSetManager: Lost task 0.0 in stage 59435.0 (TID 35332) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:30 ERROR TaskSetManager: Task 0 in stage 59435.0 failed 1 times; aborting job\n",
      "25/06/04 08:59:34 ERROR Executor: Exception in task 0.0 in stage 59746.0 (TID 35529)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:34 WARN TaskSetManager: Lost task 0.0 in stage 59746.0 (TID 35529) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:34 ERROR TaskSetManager: Task 0 in stage 59746.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o15475.fit.\n: java.util.concurrent.ExecutionException: Error while executing workers\n\tat ai.catboost.spark.impl.Helpers$.checkOneFutureAndWaitForOther(Helpers.scala:33)\n\tat ai.catboost.spark.impl.Helpers$.waitForTwoFutures(Helpers.scala:61)\n\tat ai.catboost.spark.CatBoostPredictorTrait.$anonfun$fit$12(CatBoostPredictor.scala:260)\n\tat scala.util.control.Breaks.breakable(Breaks.scala:42)\n\tat ai.catboost.spark.CatBoostPredictorTrait.fit(CatBoostPredictor.scala:230)\n\tat ai.catboost.spark.CatBoostPredictorTrait.fit$(CatBoostPredictor.scala:125)\n\tat ai.catboost.spark.CatBoostClassifier.fit(CatBoostClassifier.scala:372)\n\tat ai.catboost.spark.CatBoostPredictorTrait.train(CatBoostPredictor.scala:111)\n\tat ai.catboost.spark.CatBoostPredictorTrait.train$(CatBoostPredictor.scala:108)\n\tat ai.catboost.spark.CatBoostClassifier.train(CatBoostClassifier.scala:372)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:114)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:78)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 59746.0 failed 1 times, most recent failure: Lost task 0.0 in stage 59746.0 (TID 35529) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1037)\n\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$9(Workers.scala:327)\n\tat ai.catboost.spark.impl.CatBoostWorkers.run(Workers.scala:178)\n\tat ai.catboost.spark.CatBoostPredictorTrait$$anon$1.run(CatBoostPredictor.scala:252)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\t... 3 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      3\u001b[39m param_grid =(ParamGridBuilder()\n\u001b[32m      4\u001b[39m             .addGrid(classifier.iterations, [\u001b[32m2000\u001b[39m,\u001b[32m5000\u001b[39m,\u001b[32m10000\u001b[39m])\n\u001b[32m      5\u001b[39m             .addGrid(classifier.depth, [\u001b[32m2\u001b[39m,\u001b[32m4\u001b[39m,\u001b[32m6\u001b[39m,\u001b[32m8\u001b[39m,\u001b[32m10\u001b[39m])\n\u001b[32m      6\u001b[39m             .addGrid(classifier.learningRate, [\u001b[32m0.001\u001b[39m,\u001b[32m0.01\u001b[39m, \u001b[32m0.05\u001b[39m, \u001b[32m0.1\u001b[39m])\n\u001b[32m      7\u001b[39m             .addGrid(classifier.l2LeafReg, [\u001b[32m1.0\u001b[39m,\u001b[32m3.0\u001b[39m,\u001b[32m5.0\u001b[39m])\n\u001b[32m      8\u001b[39m             .build())\n\u001b[32m     10\u001b[39m tvs = TrainValidationSplit(\n\u001b[32m     11\u001b[39m     estimator=classifier,\n\u001b[32m     12\u001b[39m     estimatorParamMaps=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     parallelism=\u001b[32m1\u001b[39m   \n\u001b[32m     16\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m tvs_model = \u001b[43mtvs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m best_model = tvs_model.bestModel\n\u001b[32m     20\u001b[39m prediction = best_model.transform(test_df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/ml/base.py:205\u001b[39m, in \u001b[36mEstimator.fit\u001b[39m\u001b[34m(self, dataset, params)\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(params)._fit(dataset)\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[32m    210\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/ml/tuning.py:1464\u001b[39m, in \u001b[36mTrainValidationSplit._fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m   1462\u001b[39m pool = ThreadPool(processes=\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.getParallelism(), numModels))\n\u001b[32m   1463\u001b[39m metrics = [\u001b[38;5;28;01mNone\u001b[39;00m] * numModels\n\u001b[32m-> \u001b[39m\u001b[32m1464\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubModel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimap_unordered\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcollectSubModelsParam\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/multiprocessing/pool.py:873\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m    872\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/multiprocessing/pool.py:125\u001b[39m, in \u001b[36mworker\u001b[39m\u001b[34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[39m\n\u001b[32m    123\u001b[39m job, i, func, args, kwds = task\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     result = (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/ml/tuning.py:1464\u001b[39m, in \u001b[36mTrainValidationSplit._fit.<locals>.<lambda>\u001b[39m\u001b[34m(f)\u001b[39m\n\u001b[32m   1462\u001b[39m pool = ThreadPool(processes=\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.getParallelism(), numModels))\n\u001b[32m   1463\u001b[39m metrics = [\u001b[38;5;28;01mNone\u001b[39;00m] * numModels\n\u001b[32m-> \u001b[39m\u001b[32m1464\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j, metric, subModel \u001b[38;5;129;01min\u001b[39;00m pool.imap_unordered(\u001b[38;5;28;01mlambda\u001b[39;00m f: \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, tasks):\n\u001b[32m   1465\u001b[39m     metrics[j] = metric\n\u001b[32m   1466\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m collectSubModelsParam:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/util.py:342\u001b[39m, in \u001b[36minheritable_thread_target.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    341\u001b[39m SparkContext._active_spark_context._jsc.sc().setLocalProperties(properties)\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/ml/tuning.py:113\u001b[39m, in \u001b[36m_parallelFitTasks.<locals>.singleTask\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msingleTask\u001b[39m() -> Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, Transformer]:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     index, model = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodelIter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# TODO: duplicate evaluator to take extra params from input\u001b[39;00m\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m#  Note: Supporting tuning params in evaluator need update method\u001b[39;00m\n\u001b[32m    116\u001b[39m     \u001b[38;5;66;03m#  `MetaAlgorithmReadWrite.getAllNestedStages`, make it return\u001b[39;00m\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m#  all nested stages and evaluators\u001b[39;00m\n\u001b[32m    118\u001b[39m     metric = eva.evaluate(model.transform(validation, epm[index]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/ml/base.py:98\u001b[39m, in \u001b[36m_FitMultipleIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     96\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo models remaining.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     97\u001b[39m     \u001b[38;5;28mself\u001b[39m.counter += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m index, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfitSingleModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/ml/base.py:156\u001b[39m, in \u001b[36mEstimator.fitMultiple.<locals>.fitSingleModel\u001b[39m\u001b[34m(index)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfitSingleModel\u001b[39m(index: \u001b[38;5;28mint\u001b[39m) -> M:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparamMaps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/spark-45cdb505-07cf-4b2a-ab8a-894411af548c/userFiles-01b1655b-03e9-475a-922a-6a306a6e4776/ai.catboost_catboost-spark_3.5_2.12-1.2.6.jar/catboost_spark/core.py:5346\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, dataset, params, evalDatasets)\u001b[39m\n\u001b[32m   5344\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m evalDatasets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5345\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mif dataset has type DataFrame no evalDatasets are supported\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m5346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mJavaEstimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5348\u001b[39m     sc = SparkContext._active_spark_context\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/ml/base.py:203\u001b[39m, in \u001b[36mEstimator.fit\u001b[39m\u001b[34m(self, dataset, params)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(params, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m params:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit(dataset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/ml/wrapper.py:381\u001b[39m, in \u001b[36mJavaEstimator._fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) -> JM:\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m     java_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m     model = \u001b[38;5;28mself\u001b[39m._create_model(java_model)\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._copyValues(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/ml/wrapper.py:378\u001b[39m, in \u001b[36mJavaEstimator._fit_java\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28mself\u001b[39m._transfer_params_to_java()\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_java_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/spark/spark-3.5.5-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o15475.fit.\n: java.util.concurrent.ExecutionException: Error while executing workers\n\tat ai.catboost.spark.impl.Helpers$.checkOneFutureAndWaitForOther(Helpers.scala:33)\n\tat ai.catboost.spark.impl.Helpers$.waitForTwoFutures(Helpers.scala:61)\n\tat ai.catboost.spark.CatBoostPredictorTrait.$anonfun$fit$12(CatBoostPredictor.scala:260)\n\tat scala.util.control.Breaks.breakable(Breaks.scala:42)\n\tat ai.catboost.spark.CatBoostPredictorTrait.fit(CatBoostPredictor.scala:230)\n\tat ai.catboost.spark.CatBoostPredictorTrait.fit$(CatBoostPredictor.scala:125)\n\tat ai.catboost.spark.CatBoostClassifier.fit(CatBoostClassifier.scala:372)\n\tat ai.catboost.spark.CatBoostPredictorTrait.train(CatBoostPredictor.scala:111)\n\tat ai.catboost.spark.CatBoostPredictorTrait.train$(CatBoostPredictor.scala:108)\n\tat ai.catboost.spark.CatBoostClassifier.train(CatBoostClassifier.scala:372)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:114)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:78)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 59746.0 failed 1 times, most recent failure: Lost task 0.0 in stage 59746.0 (TID 35529) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1037)\n\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$9(Workers.scala:327)\n\tat ai.catboost.spark.impl.CatBoostWorkers.run(Workers.scala:178)\n\tat ai.catboost.spark.CatBoostPredictorTrait$$anon$1.run(CatBoostPredictor.scala:252)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\t... 3 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 08:59:37 ERROR Executor: Exception in task 0.0 in stage 59955.0 (TID 35674)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:37 WARN TaskSetManager: Lost task 0.0 in stage 59955.0 (TID 35674) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:37 ERROR TaskSetManager: Task 0 in stage 59955.0 failed 1 times; aborting job\n",
      "25/06/04 08:59:45 ERROR Executor: Exception in task 0.0 in stage 60879.0 (TID 36177)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:45 WARN TaskSetManager: Lost task 0.0 in stage 60879.0 (TID 36177) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:45 ERROR TaskSetManager: Task 0 in stage 60879.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27s\n",
      "922:\tlearn: 0.8307688\ttotal: 4m 40s\tremaining: 5m 26s\n",
      "923:\tlearn: 0.8305868\ttotal: 4m 40s\tremaining: 5m 26s\n",
      "924:\tlearn: 0.8303424\ttotal: 4m 40s\tremaining: 5m 26s\n",
      "925:\tlearn: 0.8300747\ttotal: 4m 41s\tremaining: 5m 26s\n",
      "926:\tlearn: 0.8298102\ttotal: 4m 41s\tremaining: 5m 26s\n",
      "927:\tlearn: 0.8295685\ttotal: 4m 42s\tremaining: 5m 25s\n",
      "928:\tlearn: 0.8294258\ttotal: 4m 42s\tremaining: 5m 25s\n",
      "929:\tlearn: 0.8293313\ttotal: 4m 42s\tremaining: 5m 24s\n",
      "930:\tlearn: 0.8291552\ttotal: 4m 42s\tremaining: 5m 24s\n",
      "931:\tlearn: 0.8290803\ttotal: 4m 42s\tremaining: 5m 24s\n",
      "932:\tlearn: 0.8287933\ttotal: 4m 43s\tremaining: 5m 23s\n",
      "933:\tlearn: 0.8284699\ttotal: 4m 43s\tremaining: 5m 23s\n",
      "934:\tlearn: 0.8282846\ttotal: 4m 44s\tremaining: 5m 23s\n",
      "935:\tlearn: 0.8281607\ttotal: 4m 44s\tremaining: 5m 23s\n",
      "936:\tlearn: 0.8279240\ttotal: 4m 44s\tremaining: 5m 22s\n",
      "937:\tlearn: 0.8278335\ttotal: 4m 44s\tremaining: 5m 22s\n",
      "938:\tlearn: 0.8277350\ttotal: 4m 45s\tremaining: 5m 22s\n",
      "939:\tlearn: 0.8275708\ttotal: 4m 45s\tremaining: 5m 21s\n",
      "940:\tlearn: 0.8272906\ttotal: 4m 45s\tremaining: 5m 21s\n",
      "941:\tlearn: 0.8269906\ttotal: 4m 46s\tremaining: 5m 21s\n",
      "942:\tlearn: 0.8267150\ttotal: 4m 46s\tremaining: 5m 21s\n",
      "943:\tlearn: 0.8266213\ttotal: 4m 46s\tremaining: 5m 20s\n",
      "944:\tlearn: 0.8263566\ttotal: 4m 47s\tremaining: 5m 20s\n",
      "945:\tlearn: 0.8261230\ttotal: 4m 47s\tremaining: 5m 20s\n",
      "946:\tlearn: 0.8258287\ttotal: 4m 48s\tremaining: 5m 20s\n",
      "947:\tlearn: 0.8257349\ttotal: 4m 48s\tremaining: 5m 20s\n",
      "948:\tlearn: 0.8254316\ttotal: 4m 48s\tremaining: 5m 20s\n",
      "949:\tlearn: 0.8251317\ttotal: 4m 49s\tremaining: 5m 20s\n",
      "950:\tlearn: 0.8248688\ttotal: 4m 50s\tremaining: 5m 19s\n",
      "951:\tlearn: 0.8245888\ttotal: 4m 50s\tremaining: 5m 19s\n",
      "952:\tlearn: 0.8243265\ttotal: 4m 51s\tremaining: 5m 19s\n",
      "953:\tlearn: 0.8239935\ttotal: 4m 51s\tremaining: 5m 19s\n",
      "954:\tlearn: 0.8237152\ttotal: 4m 52s\tremaining: 5m 19s\n",
      "955:\tlearn: 0.8234824\ttotal: 4m 52s\tremaining: 5m 19s\n",
      "956:\tlearn: 0.8231952\ttotal: 4m 53s\tremaining: 5m 19s\n",
      "957:\tlearn: 0.8231239\ttotal: 4m 53s\tremaining: 5m 18s\n",
      "958:\tlearn: 0.8228982\ttotal: 4m 53s\tremaining: 5m 18s\n",
      "959:\tlearn: 0.8226270\ttotal: 4m 54s\tremaining: 5m 18s\n",
      "960:\tlearn: 0.8223344\ttotal: 4m 54s\tremaining: 5m 18s\n",
      "961:\tlearn: 0.8221061\ttotal: 4m 55s\tremaining: 5m 18s\n",
      "962:\tlearn: 0.8217804\ttotal: 4m 55s\tremaining: 5m 18s\n",
      "963:\tlearn: 0.8215022\ttotal: 4m 56s\tremaining: 5m 18s\n",
      "964:\tlearn: 0.8212189\ttotal: 4m 56s\tremaining: 5m 18s\n",
      "965:\tlearn: 0.8210094\ttotal: 4m 57s\tremaining: 5m 18s\n",
      "966:\tlearn: 0.8207292\ttotal: 4m 57s\tremaining: 5m 18s\n",
      "967:\tlearn: 0.8204592\ttotal: 4m 58s\tremaining: 5m 18s\n",
      "968:\tlearn: 0.8201726\ttotal: 4m 59s\tremaining: 5m 18s\n",
      "969:\tlearn: 0.8199692\ttotal: 4m 59s\tremaining: 5m 18s\n",
      "970:\tlearn: 0.8198965\ttotal: 4m 59s\tremaining: 5m 17s\n",
      "971:\tlearn: 0.8197772\ttotal: 4m 59s\tremaining: 5m 17s\n",
      "972:\tlearn: 0.8195440\ttotal: 5m\tremaining: 5m 17s\n",
      "973:\tlearn: 0.8193405\ttotal: 5m\tremaining: 5m 17s\n",
      "974:\tlearn: 0.8191541\ttotal: 5m 1s\tremaining: 5m 16s\n",
      "975:\tlearn: 0.8188902\ttotal: 5m 1s\tremaining: 5m 16s\n",
      "976:\tlearn: 0.8187461\ttotal: 5m 2s\tremaining: 5m 16s\n",
      "977:\tlearn: 0.8186536\ttotal: 5m 2s\tremaining: 5m 15s\n",
      "978:\tlearn: 0.8183509\ttotal: 5m 2s\tremaining: 5m 15s\n",
      "979:\tlearn: 0.8181231\ttotal: 5m 3s\tremaining: 5m 15s\n",
      "980:\tlearn: 0.8178298\ttotal: 5m 3s\tremaining: 5m 15s\n",
      "981:\tlearn: 0.8175360\ttotal: 5m 4s\tremaining: 5m 15s\n",
      "982:\tlearn: 0.8173231\ttotal: 5m 4s\tremaining: 5m 15s\n",
      "983:\tlearn: 0.8171761\ttotal: 5m 4s\tremaining: 5m 14s\n",
      "984:\tlearn: 0.8169013\ttotal: 5m 5s\tremaining: 5m 14s\n",
      "985:\tlearn: 0.8167090\ttotal: 5m 5s\tremaining: 5m 14s\n",
      "986:\tlearn: 0.8164809\ttotal: 5m 6s\tremaining: 5m 14s\n",
      "987:\tlearn: 0.8161850\ttotal: 5m 6s\tremaining: 5m 14s\n",
      "988:\tlearn: 0.8159393\ttotal: 5m 7s\tremaining: 5m 14s\n",
      "989:\tlearn: 0.8156976\ttotal: 5m 7s\tremaining: 5m 14s\n",
      "990:\tlearn: 0.8154200\ttotal: 5m 8s\tremaining: 5m 13s\n",
      "991:\tlearn: 0.8153257\ttotal: 5m 8s\tremaining: 5m 13s\n",
      "992:\tlearn: 0.8150607\ttotal: 5m 9s\tremaining: 5m 13s\n",
      "993:\tlearn: 0.8147554\ttotal: 5m 9s\tremaining: 5m 13s\n",
      "994:\tlearn: 0.8145695\ttotal: 5m 10s\tremaining: 5m 13s\n",
      "995:\tlearn: 0.8145008\ttotal: 5m 10s\tremaining: 5m 12s\n",
      "996:\tlearn: 0.8143895\ttotal: 5m 10s\tremaining: 5m 12s\n",
      "997:\tlearn: 0.8141214\ttotal: 5m 10s\tremaining: 5m 12s\n",
      "998:\tlearn: 0.81"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 08:59:52 ERROR Executor: Exception in task 0.0 in stage 61628.0 (TID 36609)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:52 WARN TaskSetManager: Lost task 0.0 in stage 61628.0 (TID 36609) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:52 ERROR TaskSetManager: Task 0 in stage 61628.0 failed 1 times; aborting job\n",
      "25/06/04 08:59:54 ERROR Executor: Exception in task 0.0 in stage 61724.0 (TID 36679)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:54 WARN TaskSetManager: Lost task 0.0 in stage 61724.0 (TID 36679) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:54 ERROR TaskSetManager: Task 0 in stage 61724.0 failed 1 times; aborting job\n",
      "25/06/04 08:59:58 ERROR Executor: Exception in task 0.0 in stage 62133.0 (TID 36927)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 08:59:58 WARN TaskSetManager: Lost task 0.0 in stage 62133.0 (TID 36927) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 08:59:58 ERROR TaskSetManager: Task 0 in stage 62133.0 failed 1 times; aborting job\n",
      "25/06/04 09:00:03 ERROR Executor: Exception in task 0.0 in stage 62445.0 (TID 37124)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:00:03 WARN TaskSetManager: Lost task 0.0 in stage 62445.0 (TID 37124) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:00:03 ERROR TaskSetManager: Task 0 in stage 62445.0 failed 1 times; aborting job\n",
      "25/06/04 09:00:07 ERROR Executor: Exception in task 0.0 in stage 62746.0 (TID 37317)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:00:07 WARN TaskSetManager: Lost task 0.0 in stage 62746.0 (TID 37317) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:00:07 ERROR TaskSetManager: Task 0 in stage 62746.0 failed 1 times; aborting job\n",
      "25/06/04 09:00:10 ERROR Executor: Exception in task 0.0 in stage 62897.0 (TID 37431)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:00:10 WARN TaskSetManager: Lost task 0.0 in stage 62897.0 (TID 37431) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:00:10 ERROR TaskSetManager: Task 0 in stage 62897.0 failed 1 times; aborting job\n",
      "25/06/04 09:00:18 ERROR Executor: Exception in task 0.0 in stage 63881.0 (TID 37965)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:00:18 WARN TaskSetManager: Lost task 0.0 in stage 63881.0 (TID 37965) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:00:18 ERROR TaskSetManager: Task 0 in stage 63881.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39601\ttotal: 5m 11s\tremaining: 5m 11s\n",
      "999:\tlearn: 0.8138792\ttotal: 5m 11s\tremaining: 5m 11s\n",
      "1000:\tlearn: 0.8136150\ttotal: 5m 12s\tremaining: 5m 11s\n",
      "1001:\tlearn: 0.8133538\ttotal: 5m 12s\tremaining: 5m 11s\n",
      "1002:\tlearn: 0.8130909\ttotal: 5m 13s\tremaining: 5m 11s\n",
      "1003:\tlearn: 0.8129396\ttotal: 5m 13s\tremaining: 5m 10s\n",
      "1004:\tlearn: 0.8126796\ttotal: 5m 14s\tremaining: 5m 10s\n",
      "1005:\tlearn: 0.8123885\ttotal: 5m 14s\tremaining: 5m 10s\n",
      "1006:\tlearn: 0.8121544\ttotal: 5m 15s\tremaining: 5m 10s\n",
      "1007:\tlearn: 0.8118333\ttotal: 5m 15s\tremaining: 5m 10s\n",
      "1008:\tlearn: 0.8117655\ttotal: 5m 15s\tremaining: 5m 10s\n",
      "1009:\tlearn: 0.8116638\ttotal: 5m 15s\tremaining: 5m 9s\n",
      "1010:\tlearn: 0.8113661\ttotal: 5m 16s\tremaining: 5m 9s\n",
      "1011:\tlearn: 0.8111793\ttotal: 5m 16s\tremaining: 5m 9s\n",
      "1012:\tlearn: 0.8109385\ttotal: 5m 17s\tremaining: 5m 9s\n",
      "1013:\tlearn: 0.8107985\ttotal: 5m 17s\tremaining: 5m 9s\n",
      "1014:\tlearn: 0.8107266\ttotal: 5m 17s\tremaining: 5m 8s\n",
      "1015:\tlearn: 0.8106287\ttotal: 5m 18s\tremaining: 5m 8s\n",
      "1016:\tlearn: 0.8103686\ttotal: 5m 18s\tremaining: 5m 8s\n",
      "1017:\tlearn: 0.8100684\ttotal: 5m 19s\tremaining: 5m 7s\n",
      "1018:\tlearn: 0.8098292\ttotal: 5m 19s\tremaining: 5m 7s\n",
      "1019:\tlearn: 0.8095598\ttotal: 5m 20s\tremaining: 5m 7s\n",
      "1020:\tlearn: 0.8093004\ttotal: 5m 20s\tremaining: 5m 7s\n",
      "1021:\tlearn: 0.8091208\ttotal: 5m 21s\tremaining: 5m 7s\n",
      "1022:\tlearn: 0.8089953\ttotal: 5m 21s\tremaining: 5m 6s\n",
      "1023:\tlearn: 0.8088979\ttotal: 5m 21s\tremaining: 5m 6s\n",
      "1024:\tlearn: 0.8087297\ttotal: 5m 21s\tremaining: 5m 6s\n",
      "1025:\tlearn: 0.8084976\ttotal: 5m 22s\tremaining: 5m 5s\n",
      "1026:\tlearn: 0.8082877\ttotal: 5m 22s\tremaining: 5m 5s\n",
      "1027:\tlearn: 0.8080525\ttotal: 5m 23s\tremaining: 5m 5s\n",
      "1028:\tlearn: 0.8079369\ttotal: 5m 23s\tremaining: 5m 5s\n",
      "1029:\tlearn: 0.8076642\ttotal: 5m 24s\tremaining: 5m 5s\n",
      "1030:\tlearn: 0.8075899\ttotal: 5m 24s\tremaining: 5m 4s\n",
      "1031:\tlearn: 0.8073308\ttotal: 5m 24s\tremaining: 5m 4s\n",
      "1032:\tlearn: 0.8072383\ttotal: 5m 25s\tremaining: 5m 4s\n",
      "1033:\tlearn: 0.8069342\ttotal: 5m 25s\tremaining: 5m 4s\n",
      "1034:\tlearn: 0.8068683\ttotal: 5m 25s\tremaining: 5m 3s\n",
      "1035:\tlearn: 0.8066236\ttotal: 5m 26s\tremaining: 5m 3s\n",
      "1036:\tlearn: 0.8063989\ttotal: 5m 26s\tremaining: 5m 3s\n",
      "1037:\tlearn: 0.8060897\ttotal: 5m 27s\tremaining: 5m 3s\n",
      "1038:\tlearn: 0.8058379\ttotal: 5m 27s\tremaining: 5m 3s\n",
      "1039:\tlearn: 0.8056688\ttotal: 5m 28s\tremaining: 5m 2s\n",
      "1040:\tlearn: 0.8053798\ttotal: 5m 28s\tremaining: 5m 2s\n",
      "1041:\tlearn: 0.8053143\ttotal: 5m 28s\tremaining: 5m 2s\n",
      "1042:\tlearn: 0.8052490\ttotal: 5m 28s\tremaining: 5m 1s\n",
      "1043:\tlearn: 0.8050102\ttotal: 5m 29s\tremaining: 5m 1s\n",
      "1044:\tlearn: 0.8047584\ttotal: 5m 29s\tremaining: 5m 1s\n",
      "1045:\tlearn: 0.8045083\ttotal: 5m 30s\tremaining: 5m 1s\n",
      "1046:\tlearn: 0.8042177\ttotal: 5m 30s\tremaining: 5m 1s\n",
      "1047:\tlearn: 0.8039883\ttotal: 5m 31s\tremaining: 5m 1s\n",
      "1048:\tlearn: 0.8037740\ttotal: 5m 31s\tremaining: 5m\n",
      "1049:\tlearn: 0.8034842\ttotal: 5m 32s\tremaining: 5m\n",
      "1050:\tlearn: 0.8031831\ttotal: 5m 33s\tremaining: 5m\n",
      "1051:\tlearn: 0.8030181\ttotal: 5m 33s\tremaining: 5m\n",
      "1052:\tlearn: 0.8028321\ttotal: 5m 33s\tremaining: 5m\n",
      "1053:\tlearn: 0.8025676\ttotal: 5m 34s\tremaining: 5m\n",
      "1054:\tlearn: 0.8023141\ttotal: 5m 34s\tremaining: 4m 59s\n",
      "1055:\tlearn: 0.8020673\ttotal: 5m 35s\tremaining: 4m 59s\n",
      "1056:\tlearn: 0.8017778\ttotal: 5m 35s\tremaining: 4m 59s\n",
      "1057:\tlearn: 0.8017065\ttotal: 5m 36s\tremaining: 4m 59s\n",
      "1058:\tlearn: 0.8015333\ttotal: 5m 36s\tremaining: 4m 59s\n",
      "1059:\tlearn: 0.8013136\ttotal: 5m 36s\tremaining: 4m 58s\n",
      "1060:\tlearn: 0.8010850\ttotal: 5m 37s\tremaining: 4m 58s\n",
      "1061:\tlearn: 0.8008143\ttotal: 5m 37s\tremaining: 4m 58s\n",
      "1062:\tlearn: 0.8005442\ttotal: 5m 38s\tremaining: 4m 58s\n",
      "1063:\tlearn: 0.8003977\ttotal: 5m 38s\tremaining: 4m 58s\n",
      "1064:\tlearn: 0.8002737\ttotal: 5m 39s\tremaining: 4m 57s\n",
      "1065:\tlearn: 0.8000015\ttotal: 5m 39s\tremaining: 4m 57s\n",
      "1066:\tlearn: 0.7998931\ttotal: 5m 39s\tremaining: 4m 57s\n",
      "1067:\tlearn: 0.7997566\ttotal: 5m 40s\tremaining: 4m 56s\n",
      "1068:\tlearn: 0.7995214\ttotal: 5m 40s\tremaining: 4m 56s\n",
      "1069:\tlearn: 0.7992538\ttotal: 5m 41s\tremaining: 4m 56s\n",
      "1070:\tlearn: 0.7991001\ttotal: 5m 41s\tremaining: 4m 56s\n",
      "1071:\tlearn: 0.7988888\ttotal: 5m 41s\tremaining: 4m 55s\n",
      "1072:\tlearn: 0.7986613\ttotal: 5m 42s\tremaining: 4m 55s\n",
      "1073:\tlearn: 0.7983855\ttotal: 5m 42s\tremaining: 4m 5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 09:00:24 ERROR Executor: Exception in task 0.0 in stage 64580.0 (TID 38357)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:00:24 WARN TaskSetManager: Lost task 0.0 in stage 64580.0 (TID 38357) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:00:24 ERROR TaskSetManager: Task 0 in stage 64580.0 failed 1 times; aborting job\n",
      "25/06/04 09:00:27 ERROR Executor: Exception in task 0.0 in stage 64725.0 (TID 38468)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:00:27 WARN TaskSetManager: Lost task 0.0 in stage 64725.0 (TID 38468) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:00:27 ERROR TaskSetManager: Task 0 in stage 64725.0 failed 1 times; aborting job\n",
      "25/06/04 09:00:34 ERROR Executor: Exception in task 0.0 in stage 65137.0 (TID 38716)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:00:34 WARN TaskSetManager: Lost task 0.0 in stage 65137.0 (TID 38716) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:00:34 ERROR TaskSetManager: Task 0 in stage 65137.0 failed 1 times; aborting job\n",
      "25/06/04 09:00:42 ERROR Executor: Exception in task 0.0 in stage 65477.0 (TID 38927)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:00:42 WARN TaskSetManager: Lost task 0.0 in stage 65477.0 (TID 38927) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:00:42 ERROR TaskSetManager: Task 0 in stage 65477.0 failed 1 times; aborting job\n",
      "25/06/04 09:00:51 ERROR Executor: Exception in task 0.0 in stage 65828.0 (TID 39163)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:00:51 WARN TaskSetManager: Lost task 0.0 in stage 65828.0 (TID 39163) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:00:51 ERROR TaskSetManager: Task 0 in stage 65828.0 failed 1 times; aborting job\n",
      "25/06/04 09:00:52 ERROR Executor: Exception in task 0.0 in stage 65902.0 (TID 39217)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:00:52 WARN TaskSetManager: Lost task 0.0 in stage 65902.0 (TID 39217) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:00:52 ERROR TaskSetManager: Task 0 in stage 65902.0 failed 1 times; aborting job\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5s\n",
      "1074:\tlearn: 0.7981857\ttotal: 5m 43s\tremaining: 4m 55s\n",
      "1075:\tlearn: 0.7979155\ttotal: 5m 43s\tremaining: 4m 55s\n",
      "1076:\tlearn: 0.7976666\ttotal: 5m 44s\tremaining: 4m 55s\n",
      "1077:\tlearn: 0.7974585\ttotal: 5m 44s\tremaining: 4m 54s\n",
      "1078:\tlearn: 0.7973640\ttotal: 5m 44s\tremaining: 4m 54s\n",
      "1079:\tlearn: 0.7972429\ttotal: 5m 45s\tremaining: 4m 54s\n",
      "1080:\tlearn: 0.7969338\ttotal: 5m 45s\tremaining: 4m 54s\n",
      "1081:\tlearn: 0.7966903\ttotal: 5m 46s\tremaining: 4m 53s\n",
      "1082:\tlearn: 0.7964227\ttotal: 5m 46s\tremaining: 4m 53s\n",
      "1083:\tlearn: 0.7961578\ttotal: 5m 47s\tremaining: 4m 53s\n",
      "1084:\tlearn: 0.7958627\ttotal: 5m 48s\tremaining: 4m 53s\n",
      "1085:\tlearn: 0.7956215\ttotal: 5m 48s\tremaining: 4m 53s\n",
      "1086:\tlearn: 0.7953362\ttotal: 5m 49s\tremaining: 4m 53s\n",
      "1087:\tlearn: 0.7950547\ttotal: 5m 49s\tremaining: 4m 53s\n",
      "1088:\tlearn: 0.7947947\ttotal: 5m 50s\tremaining: 4m 53s\n",
      "1089:\tlearn: 0.7945505\ttotal: 5m 50s\tremaining: 4m 52s\n",
      "1090:\tlearn: 0.7942917\ttotal: 5m 51s\tremaining: 4m 52s\n",
      "1091:\tlearn: 0.7940609\ttotal: 5m 52s\tremaining: 4m 52s\n",
      "1092:\tlearn: 0.7938170\ttotal: 5m 52s\tremaining: 4m 52s\n",
      "1093:\tlearn: 0.7935409\ttotal: 5m 53s\tremaining: 4m 52s\n",
      "1094:\tlearn: 0.7933123\ttotal: 5m 54s\tremaining: 4m 53s\n",
      "1095:\tlearn: 0.7930637\ttotal: 5m 55s\tremaining: 4m 53s\n",
      "1096:\tlearn: 0.7928564\ttotal: 5m 56s\tremaining: 4m 53s\n",
      "1097:\tlearn: 0.7925982\ttotal: 5m 56s\tremaining: 4m 53s\n",
      "1098:\tlearn: 0.7925097\ttotal: 5m 57s\tremaining: 4m 52s\n",
      "1099:\tlearn: 0.7923338\ttotal: 5m 57s\tremaining: 4m 52s\n",
      "1100:\tlearn: 0.7922283\ttotal: 5m 58s\tremaining: 4m 52s\n",
      "1101:\tlearn: 0.7920079\ttotal: 5m 58s\tremaining: 4m 52s\n",
      "1102:\tlearn: 0.7917789\ttotal: 5m 59s\tremaining: 4m 52s\n",
      "1103:\tlearn: 0.7915736\ttotal: 6m\tremaining: 4m 52s\n",
      "1104:\tlearn: 0.7912789\ttotal: 6m 1s\tremaining: 4m 52s\n",
      "1105:\tlearn: 0.7910101\ttotal: 6m 2s\tremaining: 4m 52s\n",
      "1106:\tlearn: 0.7908030\ttotal: 6m 2s\tremaining: 4m 52s\n",
      "1107:\tlearn: 0.7906150\ttotal: 6m 3s\tremaining: 4m 52s\n",
      "1108:\tlearn: 0.7903900\ttotal: 6m 4s\tremaining: 4m 52s\n",
      "1109:\tlearn: 0.7902008\ttotal: 6m 4s\tremaining: 4m 52s\n",
      "1110:\tlearn: 0.7901395\ttotal: 6m 4s\tremaining: 4m 51s\n",
      "1111:\tlearn: 0.7898528\ttotal: 6m 5s\tremaining: 4m 51s\n",
      "1112:\tlearn: 0.7895656\ttotal: 6m 6s\tremaining: 4m 52s\n",
      "1113:\tlearn: 0.7893556\ttotal: 6m 7s\tremaining: 4m 52s\n",
      "1114:\tlearn: 0.7891107\ttotal: 6m 8s\tremaining: 4m 52s\n",
      "1115:\tlearn: 0.7890235\ttotal: 6m 8s\tremaining: 4m 51s\n",
      "1116:\tlearn: 0.7889591\ttotal: 6m 8s\tremaining: 4m 51s\n",
      "1117:\tlearn: 0.7887064\ttotal: 6m 9s\tremaining: 4m 51s\n",
      "1118:\tlearn: 0.7885841\ttotal: 6m 9s\tremaining: 4m 51s\n",
      "1119:\tlearn: 0.7882885\ttotal: 6m 10s\tremaining: 4m 51s\n",
      "1120:\tlearn: 0.7881879\ttotal: 6m 10s\tremaining: 4m 50s\n",
      "1121:\tlearn: 0.7879572\ttotal: 6m 11s\tremaining: 4m 50s\n",
      "1122:\tlearn: 0.7877763\ttotal: 6m 12s\tremaining: 4m 50s\n",
      "1123:\tlearn: 0.7876424\ttotal: 6m 12s\tremaining: 4m 50s\n",
      "1124:\tlearn: 0.7874049\ttotal: 6m 13s\tremaining: 4m 50s\n",
      "1125:\tlearn: 0.7871946\ttotal: 6m 14s\tremaining: 4m 50s\n",
      "1126:\tlearn: 0.7870981\ttotal: 6m 14s\tremaining: 4m 50s\n",
      "1127:\tlearn: 0.7868648\ttotal: 6m 15s\tremaining: 4m 50s\n",
      "1128:\tlearn: 0.7866346\ttotal: 6m 16s\tremaining: 4m 50s\n",
      "1129:\tlearn: 0.7864594\ttotal: 6m 16s\tremaining: 4m 50s\n",
      "1130:\tlearn: 0.7861999\ttotal: 6m 17s\tremaining: 4m 50s\n",
      "1131:\tlearn: 0.7860615\ttotal: 6m 17s\tremaining: 4m 49s\n",
      "1132:\tlearn: 0.7859157\ttotal: 6m 18s\tremaining: 4m 49s\n",
      "1133:\tlearn: 0.7857031\ttotal: 6m 19s\tremaining: 4m 49s\n",
      "1134:\tlearn: 0.7854865\ttotal: 6m 20s\tremaining: 4m 49s\n",
      "1135:\tlearn: 0.7854268\ttotal: 6m 20s\tremaining: 4m 49s\n",
      "1136:\tlearn: 0.7852996\ttotal: 6m 20s\tremaining: 4m 48s\n",
      "1137:\tlearn: 0.7850574\ttotal: 6m 21s\tremaining: 4m 48s\n",
      "1138:\tlearn: 0.7848607\ttotal: 6m 21s\tremaining: 4m 48s\n",
      "1139:\tlearn: 0.7846488\ttotal: 6m 22s\tremaining: 4m 48s\n",
      "1140:\tlearn: 0.7843878\ttotal: 6m 23s\tremaining: 4m 48s\n",
      "1141:\tlearn: 0.7843125\ttotal: 6m 23s\tremaining: 4m 47s\n",
      "1142:\tlearn: 0.7842060\ttotal: 6m 23s\tremaining: 4m 47s\n",
      "1143:\tlearn: 0.7840129\ttotal: 6m 24s\tremaining: 4m 47s\n",
      "1144:\tlearn: 0.7838663\ttotal: 6m 25s\tremaining: 4m 47s\n",
      "1145:\tlearn: 0.7836137\ttotal: 6m 26s\tremaining: 4m 47s\n",
      "1146:\tlearn: 0.7833493\ttotal: 6m 26s\tremaining: 4m 47s\n",
      "1147:\tlearn: 0.7831354\ttotal: 6m 27s\tremaining: 4m 47s\n",
      "1148:\tlearn: 0.7829149\ttotal: 6m 28s\tremai"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 09:01:06 ERROR Executor: Exception in task 0.0 in stage 66807.0 (TID 39715)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:01:06 WARN TaskSetManager: Lost task 0.0 in stage 66807.0 (TID 39715) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:01:06 ERROR TaskSetManager: Task 0 in stage 66807.0 failed 1 times; aborting job\n",
      "25/06/04 09:01:21 ERROR Executor: Exception in task 0.0 in stage 67628.0 (TID 40184)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:01:21 WARN TaskSetManager: Lost task 0.0 in stage 67628.0 (TID 40184) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:01:21 ERROR TaskSetManager: Task 0 in stage 67628.0 failed 1 times; aborting job\n",
      "25/06/04 09:01:23 ERROR Executor: Exception in task 0.0 in stage 67720.0 (TID 40250)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:01:23 WARN TaskSetManager: Lost task 0.0 in stage 67720.0 (TID 40250) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:01:23 ERROR TaskSetManager: Task 0 in stage 67720.0 failed 1 times; aborting job\n",
      "25/06/04 09:01:28 ERROR Executor: Exception in task 0.0 in stage 68141.0 (TID 40505)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:01:28 WARN TaskSetManager: Lost task 0.0 in stage 68141.0 (TID 40505) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:01:28 ERROR TaskSetManager: Task 0 in stage 68141.0 failed 1 times; aborting job\n",
      "25/06/04 09:01:32 ERROR Executor: Exception in task 0.0 in stage 68425.0 (TID 40688)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:01:32 WARN TaskSetManager: Lost task 0.0 in stage 68425.0 (TID 40688) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:01:32 ERROR TaskSetManager: Task 0 in stage 68425.0 failed 1 times; aborting job\n",
      "25/06/04 09:01:39 ERROR Executor: Exception in task 0.0 in stage 68860.0 (TID 40975)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:01:39 WARN TaskSetManager: Lost task 0.0 in stage 68860.0 (TID 40975) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:01:39 ERROR TaskSetManager: Task 0 in stage 68860.0 failed 1 times; aborting job\n",
      "25/06/04 09:01:40 ERROR Executor: Exception in task 0.0 in stage 68896.0 (TID 41001)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:01:40 WARN TaskSetManager: Lost task 0.0 in stage 68896.0 (TID 41001) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:01:40 ERROR TaskSetManager: Task 0 in stage 68896.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ning: 4m 47s\n",
      "1149:\tlearn: 0.7826604\ttotal: 6m 29s\tremaining: 4m 47s\n",
      "1150:\tlearn: 0.7825764\ttotal: 6m 29s\tremaining: 4m 47s\n",
      "1151:\tlearn: 0.7824013\ttotal: 6m 30s\tremaining: 4m 47s\n",
      "1152:\tlearn: 0.7822017\ttotal: 6m 30s\tremaining: 4m 47s\n",
      "1153:\tlearn: 0.7821290\ttotal: 6m 31s\tremaining: 4m 46s\n",
      "1154:\tlearn: 0.7820089\ttotal: 6m 31s\tremaining: 4m 46s\n",
      "1155:\tlearn: 0.7819463\ttotal: 6m 31s\tremaining: 4m 46s\n",
      "1156:\tlearn: 0.7817138\ttotal: 6m 32s\tremaining: 4m 46s\n",
      "1157:\tlearn: 0.7815515\ttotal: 6m 33s\tremaining: 4m 45s\n",
      "1158:\tlearn: 0.7813028\ttotal: 6m 34s\tremaining: 4m 45s\n",
      "1159:\tlearn: 0.7811745\ttotal: 6m 34s\tremaining: 4m 45s\n",
      "1160:\tlearn: 0.7809477\ttotal: 6m 35s\tremaining: 4m 45s\n",
      "1161:\tlearn: 0.7807304\ttotal: 6m 36s\tremaining: 4m 45s\n",
      "1162:\tlearn: 0.7804564\ttotal: 6m 37s\tremaining: 4m 45s\n",
      "1163:\tlearn: 0.7802565\ttotal: 6m 37s\tremaining: 4m 45s\n",
      "1164:\tlearn: 0.7799618\ttotal: 6m 38s\tremaining: 4m 45s\n",
      "1165:\tlearn: 0.7796885\ttotal: 6m 39s\tremaining: 4m 45s\n",
      "1166:\tlearn: 0.7794798\ttotal: 6m 40s\tremaining: 4m 45s\n",
      "1167:\tlearn: 0.7792808\ttotal: 6m 41s\tremaining: 4m 45s\n",
      "1168:\tlearn: 0.7791322\ttotal: 6m 41s\tremaining: 4m 45s\n",
      "1169:\tlearn: 0.7789812\ttotal: 6m 42s\tremaining: 4m 45s\n",
      "1170:\tlearn: 0.7787238\ttotal: 6m 42s\tremaining: 4m 45s\n",
      "1171:\tlearn: 0.7784774\ttotal: 6m 43s\tremaining: 4m 45s\n",
      "1172:\tlearn: 0.7782463\ttotal: 6m 44s\tremaining: 4m 45s\n",
      "1173:\tlearn: 0.7781408\ttotal: 6m 44s\tremaining: 4m 44s\n",
      "1174:\tlearn: 0.7779143\ttotal: 6m 45s\tremaining: 4m 44s\n",
      "1175:\tlearn: 0.7776610\ttotal: 6m 46s\tremaining: 4m 44s\n",
      "1176:\tlearn: 0.7773765\ttotal: 6m 46s\tremaining: 4m 44s\n",
      "1177:\tlearn: 0.7771521\ttotal: 6m 47s\tremaining: 4m 44s\n",
      "1178:\tlearn: 0.7769275\ttotal: 6m 47s\tremaining: 4m 43s\n",
      "1179:\tlearn: 0.7767070\ttotal: 6m 48s\tremaining: 4m 43s\n",
      "1180:\tlearn: 0.7766498\ttotal: 6m 48s\tremaining: 4m 43s\n",
      "1181:\tlearn: 0.7764447\ttotal: 6m 49s\tremaining: 4m 43s\n",
      "1182:\tlearn: 0.7761699\ttotal: 6m 49s\tremaining: 4m 42s\n",
      "1183:\tlearn: 0.7760089\ttotal: 6m 50s\tremaining: 4m 42s\n",
      "1184:\tlearn: 0.7759244\ttotal: 6m 50s\tremaining: 4m 42s\n",
      "1185:\tlearn: 0.7756964\ttotal: 6m 50s\tremaining: 4m 42s\n",
      "1186:\tlearn: 0.7754540\ttotal: 6m 51s\tremaining: 4m 41s\n",
      "1187:\tlearn: 0.7753796\ttotal: 6m 51s\tremaining: 4m 41s\n",
      "1188:\tlearn: 0.7753229\ttotal: 6m 51s\tremaining: 4m 40s\n",
      "1189:\tlearn: 0.7751304\ttotal: 6m 52s\tremaining: 4m 40s\n",
      "1190:\tlearn: 0.7748697\ttotal: 6m 53s\tremaining: 4m 40s\n",
      "1191:\tlearn: 0.7746632\ttotal: 6m 53s\tremaining: 4m 40s\n",
      "1192:\tlearn: 0.7744819\ttotal: 6m 53s\tremaining: 4m 40s\n",
      "1193:\tlearn: 0.7742930\ttotal: 6m 54s\tremaining: 4m 39s\n",
      "1194:\tlearn: 0.7740429\ttotal: 6m 55s\tremaining: 4m 39s\n",
      "1195:\tlearn: 0.7737534\ttotal: 6m 55s\tremaining: 4m 39s\n",
      "1196:\tlearn: 0.7735774\ttotal: 6m 56s\tremaining: 4m 39s\n",
      "1197:\tlearn: 0.7735225\ttotal: 6m 56s\tremaining: 4m 38s\n",
      "1198:\tlearn: 0.7732718\ttotal: 6m 57s\tremaining: 4m 38s\n",
      "1199:\tlearn: 0.7731460\ttotal: 6m 57s\tremaining: 4m 38s\n",
      "1200:\tlearn: 0.7729062\ttotal: 6m 57s\tremaining: 4m 38s\n",
      "1201:\tlearn: 0.7728504\ttotal: 6m 58s\tremaining: 4m 37s\n",
      "1202:\tlearn: 0.7727376\ttotal: 6m 58s\tremaining: 4m 37s\n",
      "1203:\tlearn: 0.7724749\ttotal: 6m 59s\tremaining: 4m 37s\n",
      "1204:\tlearn: 0.7722295\ttotal: 6m 59s\tremaining: 4m 36s\n",
      "1205:\tlearn: 0.7720072\ttotal: 7m\tremaining: 4m 36s\n",
      "1206:\tlearn: 0.7719517\ttotal: 7m\tremaining: 4m 36s\n",
      "1207:\tlearn: 0.7718718\ttotal: 7m\tremaining: 4m 35s\n",
      "1208:\tlearn: 0.7718164\ttotal: 7m\tremaining: 4m 35s\n",
      "1209:\tlearn: 0.7715946\ttotal: 7m 1s\tremaining: 4m 35s\n",
      "1210:\tlearn: 0.7713300\ttotal: 7m 2s\tremaining: 4m 35s\n",
      "1211:\tlearn: 0.7711263\ttotal: 7m 2s\tremaining: 4m 34s\n",
      "1212:\tlearn: 0.7708825\ttotal: 7m 3s\tremaining: 4m 34s\n",
      "1213:\tlearn: 0.7707768\ttotal: 7m 3s\tremaining: 4m 34s\n",
      "1214:\tlearn: 0.7705144\ttotal: 7m 4s\tremaining: 4m 34s\n",
      "1215:\tlearn: 0.7702559\ttotal: 7m 4s\tremaining: 4m 33s\n",
      "1216:\tlearn: 0.7700314\ttotal: 7m 5s\tremaining: 4m 33s\n",
      "1217:\tlearn: 0.7698362\ttotal: 7m 5s\tremaining: 4m 33s\n",
      "1218:\tlearn: 0.7697479\ttotal: 7m 6s\tremaining: 4m 33s\n",
      "1219:\tlearn: 0.7694946\ttotal: 7m 6s\tremaining: 4m 32s\n",
      "1220:\tlearn: 0.7694144\ttotal: 7m 6s\tremaining: 4m 32s\n",
      "1221:\tlearn: 0.7691564\ttotal: 7m 7s\tremaining: 4m 32s\n",
      "1222:\tlearn: 0.7689369\ttotal: 7m 8s\tremaining: 4m 31s\n",
      "1223:\tlearn: 0.7687160\ttotal: 7m 8s\tremaini"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 09:01:49 ERROR Executor: Exception in task 0.0 in stage 69773.0 (TID 41485)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:01:49 WARN TaskSetManager: Lost task 0.0 in stage 69773.0 (TID 41485) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:01:49 ERROR TaskSetManager: Task 0 in stage 69773.0 failed 1 times; aborting job\n",
      "25/06/04 09:01:58 ERROR Executor: Exception in task 0.0 in stage 70630.0 (TID 41973)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:01:58 WARN TaskSetManager: Lost task 0.0 in stage 70630.0 (TID 41973) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:01:58 ERROR TaskSetManager: Task 0 in stage 70630.0 failed 1 times; aborting job\n",
      "25/06/04 09:02:00 ERROR Executor: Exception in task 0.0 in stage 70730.0 (TID 42044)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:00 WARN TaskSetManager: Lost task 0.0 in stage 70730.0 (TID 42044) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:00 ERROR TaskSetManager: Task 0 in stage 70730.0 failed 1 times; aborting job\n",
      "25/06/04 09:02:05 ERROR Executor: Exception in task 0.0 in stage 71125.0 (TID 42284)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:05 WARN TaskSetManager: Lost task 0.0 in stage 71125.0 (TID 42284) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:05 ERROR TaskSetManager: Task 0 in stage 71125.0 failed 1 times; aborting job\n",
      "25/06/04 09:02:10 ERROR Executor: Exception in task 0.0 in stage 71391.0 (TID 42458)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:10 WARN TaskSetManager: Lost task 0.0 in stage 71391.0 (TID 42458) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:10 ERROR TaskSetManager: Task 0 in stage 71391.0 failed 1 times; aborting job\n",
      "25/06/04 09:02:18 ERROR Executor: Exception in task 0.0 in stage 71902.0 (TID 42791)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:18 WARN TaskSetManager: Lost task 0.0 in stage 71902.0 (TID 42791) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:18 ERROR TaskSetManager: Task 0 in stage 71902.0 failed 1 times; aborting job\n",
      "25/06/04 09:02:18 ERROR Executor: Exception in task 0.0 in stage 71916.0 (TID 42798)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:18 WARN TaskSetManager: Lost task 0.0 in stage 71916.0 (TID 42798) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:18 ERROR TaskSetManager: Task 0 in stage 71916.0 failed 1 times; aborting job\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ng: 4m 31s\n",
      "1224:\tlearn: 0.7684865\ttotal: 7m 9s\tremaining: 4m 31s\n",
      "1225:\tlearn: 0.7683389\ttotal: 7m 9s\tremaining: 4m 31s\n",
      "1226:\tlearn: 0.7682081\ttotal: 7m 10s\tremaining: 4m 30s\n",
      "1227:\tlearn: 0.7679577\ttotal: 7m 10s\tremaining: 4m 30s\n",
      "1228:\tlearn: 0.7677370\ttotal: 7m 11s\tremaining: 4m 30s\n",
      "1229:\tlearn: 0.7676439\ttotal: 7m 11s\tremaining: 4m 30s\n",
      "1230:\tlearn: 0.7674446\ttotal: 7m 12s\tremaining: 4m 30s\n",
      "1231:\tlearn: 0.7672564\ttotal: 7m 13s\tremaining: 4m 30s\n",
      "1232:\tlearn: 0.7669900\ttotal: 7m 13s\tremaining: 4m 29s\n",
      "1233:\tlearn: 0.7668423\ttotal: 7m 14s\tremaining: 4m 29s\n",
      "1234:\tlearn: 0.7666537\ttotal: 7m 14s\tremaining: 4m 29s\n",
      "1235:\tlearn: 0.7664725\ttotal: 7m 15s\tremaining: 4m 29s\n",
      "1236:\tlearn: 0.7663112\ttotal: 7m 15s\tremaining: 4m 28s\n",
      "1237:\tlearn: 0.7661053\ttotal: 7m 16s\tremaining: 4m 28s\n",
      "1238:\tlearn: 0.7660357\ttotal: 7m 16s\tremaining: 4m 28s\n",
      "1239:\tlearn: 0.7657897\ttotal: 7m 17s\tremaining: 4m 28s\n",
      "1240:\tlearn: 0.7655203\ttotal: 7m 17s\tremaining: 4m 27s\n",
      "1241:\tlearn: 0.7652623\ttotal: 7m 18s\tremaining: 4m 27s\n",
      "1242:\tlearn: 0.7649667\ttotal: 7m 19s\tremaining: 4m 27s\n",
      "1243:\tlearn: 0.7648041\ttotal: 7m 19s\tremaining: 4m 27s\n",
      "1244:\tlearn: 0.7645634\ttotal: 7m 20s\tremaining: 4m 26s\n",
      "1245:\tlearn: 0.7643918\ttotal: 7m 20s\tremaining: 4m 26s\n",
      "1246:\tlearn: 0.7643070\ttotal: 7m 21s\tremaining: 4m 26s\n",
      "1247:\tlearn: 0.7640894\ttotal: 7m 21s\tremaining: 4m 26s\n",
      "1248:\tlearn: 0.7639151\ttotal: 7m 22s\tremaining: 4m 25s\n",
      "1249:\tlearn: 0.7637431\ttotal: 7m 22s\tremaining: 4m 25s\n",
      "1250:\tlearn: 0.7634590\ttotal: 7m 23s\tremaining: 4m 25s\n",
      "1251:\tlearn: 0.7632003\ttotal: 7m 23s\tremaining: 4m 25s\n",
      "1252:\tlearn: 0.7629787\ttotal: 7m 24s\tremaining: 4m 24s\n",
      "1253:\tlearn: 0.7627256\ttotal: 7m 24s\tremaining: 4m 24s\n",
      "1254:\tlearn: 0.7625877\ttotal: 7m 25s\tremaining: 4m 24s\n",
      "1255:\tlearn: 0.7624208\ttotal: 7m 25s\tremaining: 4m 24s\n",
      "1256:\tlearn: 0.7621842\ttotal: 7m 26s\tremaining: 4m 23s\n",
      "1257:\tlearn: 0.7620866\ttotal: 7m 26s\tremaining: 4m 23s\n",
      "1258:\tlearn: 0.7618843\ttotal: 7m 27s\tremaining: 4m 23s\n",
      "1259:\tlearn: 0.7616713\ttotal: 7m 27s\tremaining: 4m 22s\n",
      "1260:\tlearn: 0.7614116\ttotal: 7m 28s\tremaining: 4m 22s\n",
      "1261:\tlearn: 0.7612135\ttotal: 7m 28s\tremaining: 4m 22s\n",
      "1262:\tlearn: 0.7609878\ttotal: 7m 29s\tremaining: 4m 22s\n",
      "1263:\tlearn: 0.7607894\ttotal: 7m 30s\tremaining: 4m 22s\n",
      "1264:\tlearn: 0.7605401\ttotal: 7m 30s\tremaining: 4m 21s\n",
      "1265:\tlearn: 0.7602783\ttotal: 7m 31s\tremaining: 4m 21s\n",
      "1266:\tlearn: 0.7600465\ttotal: 7m 32s\tremaining: 4m 21s\n",
      "1267:\tlearn: 0.7599942\ttotal: 7m 32s\tremaining: 4m 21s\n",
      "1268:\tlearn: 0.7597740\ttotal: 7m 33s\tremaining: 4m 21s\n",
      "1269:\tlearn: 0.7595035\ttotal: 7m 33s\tremaining: 4m 20s\n",
      "1270:\tlearn: 0.7593369\ttotal: 7m 34s\tremaining: 4m 20s\n",
      "1271:\tlearn: 0.7592676\ttotal: 7m 34s\tremaining: 4m 20s\n",
      "1272:\tlearn: 0.7591553\ttotal: 7m 35s\tremaining: 4m 19s\n",
      "1273:\tlearn: 0.7589179\ttotal: 7m 35s\tremaining: 4m 19s\n",
      "1274:\tlearn: 0.7587780\ttotal: 7m 36s\tremaining: 4m 19s\n",
      "1275:\tlearn: 0.7587078\ttotal: 7m 36s\tremaining: 4m 18s\n",
      "1276:\tlearn: 0.7584845\ttotal: 7m 36s\tremaining: 4m 18s\n",
      "1277:\tlearn: 0.7583493\ttotal: 7m 37s\tremaining: 4m 18s\n",
      "1278:\tlearn: 0.7582895\ttotal: 7m 37s\tremaining: 4m 17s\n",
      "1279:\tlearn: 0.7580931\ttotal: 7m 37s\tremaining: 4m 17s\n",
      "1280:\tlearn: 0.7578793\ttotal: 7m 38s\tremaining: 4m 17s\n",
      "1281:\tlearn: 0.7576665\ttotal: 7m 39s\tremaining: 4m 17s\n",
      "1282:\tlearn: 0.7574520\ttotal: 7m 39s\tremaining: 4m 16s\n",
      "1283:\tlearn: 0.7571945\ttotal: 7m 40s\tremaining: 4m 16s\n",
      "1284:\tlearn: 0.7569229\ttotal: 7m 40s\tremaining: 4m 16s\n",
      "1285:\tlearn: 0.7568643\ttotal: 7m 40s\tremaining: 4m 15s\n",
      "1286:\tlearn: 0.7566410\ttotal: 7m 41s\tremaining: 4m 15s\n",
      "1287:\tlearn: 0.7565326\ttotal: 7m 41s\tremaining: 4m 15s\n",
      "1288:\tlearn: 0.7564815\ttotal: 7m 41s\tremaining: 4m 14s\n",
      "1289:\tlearn: 0.7563764\ttotal: 7m 42s\tremaining: 4m 14s\n",
      "1290:\tlearn: 0.7561547\ttotal: 7m 42s\tremaining: 4m 14s\n",
      "1291:\tlearn: 0.7560109\ttotal: 7m 42s\tremaining: 4m 13s\n",
      "1292:\tlearn: 0.7558286\ttotal: 7m 43s\tremaining: 4m 13s\n",
      "1293:\tlearn: 0.7556640\ttotal: 7m 43s\tremaining: 4m 13s\n",
      "1294:\tlearn: 0.7555629\ttotal: 7m 44s\tremaining: 4m 12s\n",
      "1295:\tlearn: 0.7554206\ttotal: 7m 44s\tremaining: 4m 12s\n",
      "1296:\tlearn: 0.7552045\ttotal: 7m 45s\tremaining: 4m 12s\n",
      "1297:\tlearn: 0.7549763\ttotal: 7m 45s\tremaining: 4m 11s\n",
      "1298:\tlearn: 0.75"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 09:02:26 ERROR Executor: Exception in task 0.0 in stage 72729.0 (TID 43250)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:26 WARN TaskSetManager: Lost task 0.0 in stage 72729.0 (TID 43250) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:26 ERROR TaskSetManager: Task 0 in stage 72729.0 failed 1 times; aborting job\n",
      "25/06/04 09:02:34 ERROR Executor: Exception in task 0.0 in stage 73636.0 (TID 43746)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:34 WARN TaskSetManager: Lost task 0.0 in stage 73636.0 (TID 43746) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:34 ERROR TaskSetManager: Task 0 in stage 73636.0 failed 1 times; aborting job\n",
      "25/06/04 09:02:36 ERROR Executor: Exception in task 0.0 in stage 73767.0 (TID 43850)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:36 WARN TaskSetManager: Lost task 0.0 in stage 73767.0 (TID 43850) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:36 ERROR TaskSetManager: Task 0 in stage 73767.0 failed 1 times; aborting job\n",
      "25/06/04 09:02:40 ERROR Executor: Exception in task 0.0 in stage 74065.0 (TID 44041)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:40 WARN TaskSetManager: Lost task 0.0 in stage 74065.0 (TID 44041) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:40 ERROR TaskSetManager: Task 0 in stage 74065.0 failed 1 times; aborting job\n",
      "25/06/04 09:02:44 ERROR Executor: Exception in task 0.0 in stage 74391.0 (TID 44245)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:44 WARN TaskSetManager: Lost task 0.0 in stage 74391.0 (TID 44245) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:44 ERROR TaskSetManager: Task 0 in stage 74391.0 failed 1 times; aborting job\n",
      "25/06/04 09:02:51 ERROR Executor: Exception in task 0.0 in stage 74890.0 (TID 44572)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:51 WARN TaskSetManager: Lost task 0.0 in stage 74890.0 (TID 44572) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:51 ERROR TaskSetManager: Task 0 in stage 74890.0 failed 1 times; aborting job\n",
      "25/06/04 09:02:51 ERROR Executor: Exception in task 0.0 in stage 74898.0 (TID 44576)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:51 WARN TaskSetManager: Lost task 0.0 in stage 74898.0 (TID 44576) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:51 ERROR TaskSetManager: Task 0 in stage 74898.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49173\ttotal: 7m 45s\tremaining: 4m 11s\n",
      "1299:\tlearn: 0.7546806\ttotal: 7m 46s\tremaining: 4m 11s\n",
      "1300:\tlearn: 0.7544529\ttotal: 7m 46s\tremaining: 4m 10s\n",
      "1301:\tlearn: 0.7542907\ttotal: 7m 47s\tremaining: 4m 10s\n",
      "1302:\tlearn: 0.7541887\ttotal: 7m 47s\tremaining: 4m 10s\n",
      "1303:\tlearn: 0.7539719\ttotal: 7m 48s\tremaining: 4m 9s\n",
      "1304:\tlearn: 0.7537318\ttotal: 7m 48s\tremaining: 4m 9s\n",
      "1305:\tlearn: 0.7534557\ttotal: 7m 49s\tremaining: 4m 9s\n",
      "1306:\tlearn: 0.7532695\ttotal: 7m 49s\tremaining: 4m 8s\n",
      "1307:\tlearn: 0.7531910\ttotal: 7m 49s\tremaining: 4m 8s\n",
      "1308:\tlearn: 0.7529638\ttotal: 7m 50s\tremaining: 4m 8s\n",
      "1309:\tlearn: 0.7526860\ttotal: 7m 50s\tremaining: 4m 8s\n",
      "1310:\tlearn: 0.7525405\ttotal: 7m 51s\tremaining: 4m 7s\n",
      "1311:\tlearn: 0.7523503\ttotal: 7m 51s\tremaining: 4m 7s\n",
      "1312:\tlearn: 0.7521015\ttotal: 7m 52s\tremaining: 4m 7s\n",
      "1313:\tlearn: 0.7519499\ttotal: 7m 52s\tremaining: 4m 6s\n",
      "1314:\tlearn: 0.7517644\ttotal: 7m 52s\tremaining: 4m 6s\n",
      "1315:\tlearn: 0.7515011\ttotal: 7m 53s\tremaining: 4m 6s\n",
      "1316:\tlearn: 0.7514115\ttotal: 7m 53s\tremaining: 4m 5s\n",
      "1317:\tlearn: 0.7512657\ttotal: 7m 54s\tremaining: 4m 5s\n",
      "1318:\tlearn: 0.7512061\ttotal: 7m 54s\tremaining: 4m 4s\n",
      "1319:\tlearn: 0.7511132\ttotal: 7m 54s\tremaining: 4m 4s\n",
      "1320:\tlearn: 0.7509094\ttotal: 7m 55s\tremaining: 4m 4s\n",
      "1321:\tlearn: 0.7506688\ttotal: 7m 55s\tremaining: 4m 3s\n",
      "1322:\tlearn: 0.7503956\ttotal: 7m 56s\tremaining: 4m 3s\n",
      "1323:\tlearn: 0.7501633\ttotal: 7m 56s\tremaining: 4m 3s\n",
      "1324:\tlearn: 0.7499641\ttotal: 7m 57s\tremaining: 4m 3s\n",
      "1325:\tlearn: 0.7498643\ttotal: 7m 57s\tremaining: 4m 2s\n",
      "1326:\tlearn: 0.7496515\ttotal: 7m 57s\tremaining: 4m 2s\n",
      "1327:\tlearn: 0.7495014\ttotal: 7m 58s\tremaining: 4m 2s\n",
      "1328:\tlearn: 0.7493369\ttotal: 7m 58s\tremaining: 4m 1s\n",
      "1329:\tlearn: 0.7491216\ttotal: 7m 59s\tremaining: 4m 1s\n",
      "1330:\tlearn: 0.7488575\ttotal: 7m 59s\tremaining: 4m 1s\n",
      "1331:\tlearn: 0.7487722\ttotal: 8m\tremaining: 4m\n",
      "1332:\tlearn: 0.7485923\ttotal: 8m\tremaining: 4m\n",
      "1333:\tlearn: 0.7485091\ttotal: 8m 1s\tremaining: 4m\n",
      "1334:\tlearn: 0.7483247\ttotal: 8m 1s\tremaining: 3m 59s\n",
      "1335:\tlearn: 0.7481016\ttotal: 8m 2s\tremaining: 3m 59s\n",
      "1336:\tlearn: 0.7479097\ttotal: 8m 2s\tremaining: 3m 59s\n",
      "1337:\tlearn: 0.7478161\ttotal: 8m 3s\tremaining: 3m 58s\n",
      "1338:\tlearn: 0.7477676\ttotal: 8m 3s\tremaining: 3m 58s\n",
      "1339:\tlearn: 0.7474925\ttotal: 8m 3s\tremaining: 3m 58s\n",
      "1340:\tlearn: 0.7473617\ttotal: 8m 4s\tremaining: 3m 57s\n",
      "1341:\tlearn: 0.7471164\ttotal: 8m 4s\tremaining: 3m 57s\n",
      "1342:\tlearn: 0.7470188\ttotal: 8m 4s\tremaining: 3m 57s\n",
      "1343:\tlearn: 0.7469478\ttotal: 8m 5s\tremaining: 3m 56s\n",
      "1344:\tlearn: 0.7467371\ttotal: 8m 5s\tremaining: 3m 56s\n",
      "1345:\tlearn: 0.7465112\ttotal: 8m 6s\tremaining: 3m 56s\n",
      "1346:\tlearn: 0.7462665\ttotal: 8m 6s\tremaining: 3m 55s\n",
      "1347:\tlearn: 0.7460143\ttotal: 8m 7s\tremaining: 3m 55s\n",
      "1348:\tlearn: 0.7458011\ttotal: 8m 7s\tremaining: 3m 55s\n",
      "1349:\tlearn: 0.7456764\ttotal: 8m 7s\tremaining: 3m 54s\n",
      "1350:\tlearn: 0.7454681\ttotal: 8m 8s\tremaining: 3m 54s\n",
      "1351:\tlearn: 0.7452576\ttotal: 8m 8s\tremaining: 3m 54s\n",
      "1352:\tlearn: 0.7449906\ttotal: 8m 9s\tremaining: 3m 53s\n",
      "1353:\tlearn: 0.7447007\ttotal: 8m 9s\tremaining: 3m 53s\n",
      "1354:\tlearn: 0.7444217\ttotal: 8m 10s\tremaining: 3m 53s\n",
      "1355:\tlearn: 0.7441274\ttotal: 8m 11s\tremaining: 3m 53s\n",
      "1356:\tlearn: 0.7439445\ttotal: 8m 11s\tremaining: 3m 52s\n",
      "1357:\tlearn: 0.7436891\ttotal: 8m 12s\tremaining: 3m 52s\n",
      "1358:\tlearn: 0.7435781\ttotal: 8m 12s\tremaining: 3m 52s\n",
      "1359:\tlearn: 0.7433475\ttotal: 8m 12s\tremaining: 3m 51s\n",
      "1360:\tlearn: 0.7431353\ttotal: 8m 13s\tremaining: 3m 51s\n",
      "1361:\tlearn: 0.7429519\ttotal: 8m 13s\tremaining: 3m 51s\n",
      "1362:\tlearn: 0.7427045\ttotal: 8m 14s\tremaining: 3m 51s\n",
      "1363:\tlearn: 0.7425858\ttotal: 8m 14s\tremaining: 3m 50s\n",
      "1364:\tlearn: 0.7423847\ttotal: 8m 15s\tremaining: 3m 50s\n",
      "1365:\tlearn: 0.7421899\ttotal: 8m 15s\tremaining: 3m 50s\n",
      "1366:\tlearn: 0.7419801\ttotal: 8m 16s\tremaining: 3m 49s\n",
      "1367:\tlearn: 0.7419328\ttotal: 8m 16s\tremaining: 3m 49s\n",
      "1368:\tlearn: 0.7417381\ttotal: 8m 16s\tremaining: 3m 48s\n",
      "1369:\tlearn: 0.7416049\ttotal: 8m 17s\tremaining: 3m 48s\n",
      "1370:\tlearn: 0.7414399\ttotal: 8m 17s\tremaining: 3m 48s\n",
      "1371:\tlearn: 0.7411953\ttotal: 8m 18s\tremaining: 3m 47s\n",
      "1372:\tlearn: 0.7409730\ttotal: 8m 18s\tremaining: 3m 47s\n",
      "1373:\tlearn: 0.7407619\ttotal: 8m 19s\tremaining: 3m 47s\n",
      "13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 09:02:58 ERROR Executor: Exception in task 0.0 in stage 75749.0 (TID 45047)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:02:58 WARN TaskSetManager: Lost task 0.0 in stage 75749.0 (TID 45047) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:02:58 ERROR TaskSetManager: Task 0 in stage 75749.0 failed 1 times; aborting job\n",
      "25/06/04 09:03:05 ERROR Executor: Exception in task 0.0 in stage 76608.0 (TID 45519)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:03:05 WARN TaskSetManager: Lost task 0.0 in stage 76608.0 (TID 45519) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:03:05 ERROR TaskSetManager: Task 0 in stage 76608.0 failed 1 times; aborting job\n",
      "25/06/04 09:03:08 ERROR Executor: Exception in task 0.0 in stage 76738.0 (TID 45621)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:03:08 WARN TaskSetManager: Lost task 0.0 in stage 76738.0 (TID 45621) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:03:08 ERROR TaskSetManager: Task 0 in stage 76738.0 failed 1 times; aborting job\n",
      "25/06/04 09:03:12 ERROR Executor: Exception in task 0.0 in stage 77039.0 (TID 45815)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:03:12 WARN TaskSetManager: Lost task 0.0 in stage 77039.0 (TID 45815) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:03:12 ERROR TaskSetManager: Task 0 in stage 77039.0 failed 1 times; aborting job\n",
      "25/06/04 09:03:16 ERROR Executor: Exception in task 0.0 in stage 77359.0 (TID 46016)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:03:16 WARN TaskSetManager: Lost task 0.0 in stage 77359.0 (TID 46016) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:03:16 ERROR TaskSetManager: Task 0 in stage 77359.0 failed 1 times; aborting job\n",
      "25/06/04 09:03:23 ERROR Executor: Exception in task 0.0 in stage 77904.0 (TID 46365)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:03:23 WARN TaskSetManager: Lost task 0.0 in stage 77904.0 (TID 46365) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:03:23 ERROR TaskSetManager: Task 0 in stage 77904.0 failed 1 times; aborting job\n",
      "25/06/04 09:03:23 ERROR Executor: Exception in task 0.0 in stage 77930.0 (TID 46379)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:03:23 WARN TaskSetManager: Lost task 0.0 in stage 77930.0 (TID 46379) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:03:23 ERROR TaskSetManager: Task 0 in stage 77930.0 failed 1 times; aborting job\n",
      "25/06/04 09:03:30 ERROR Executor: Exception in task 0.0 in stage 78723.0 (TID 46821)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:03:30 WARN TaskSetManager: Lost task 0.0 in stage 78723.0 (TID 46821) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:03:30 ERROR TaskSetManager: Task 0 in stage 78723.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74:\tlearn: 0.7405459\ttotal: 8m 19s\tremaining: 3m 47s\n",
      "1375:\tlearn: 0.7403957\ttotal: 8m 20s\tremaining: 3m 46s\n",
      "1376:\tlearn: 0.7401961\ttotal: 8m 20s\tremaining: 3m 46s\n",
      "1377:\tlearn: 0.7399966\ttotal: 8m 21s\tremaining: 3m 46s\n",
      "1378:\tlearn: 0.7399499\ttotal: 8m 21s\tremaining: 3m 45s\n",
      "1379:\tlearn: 0.7397561\ttotal: 8m 21s\tremaining: 3m 45s\n",
      "1380:\tlearn: 0.7395443\ttotal: 8m 22s\tremaining: 3m 45s\n",
      "1381:\tlearn: 0.7394977\ttotal: 8m 22s\tremaining: 3m 44s\n",
      "1382:\tlearn: 0.7392781\ttotal: 8m 23s\tremaining: 3m 44s\n",
      "1383:\tlearn: 0.7390470\ttotal: 8m 23s\tremaining: 3m 44s\n",
      "1384:\tlearn: 0.7387898\ttotal: 8m 24s\tremaining: 3m 43s\n",
      "1385:\tlearn: 0.7385925\ttotal: 8m 24s\tremaining: 3m 43s\n",
      "1386:\tlearn: 0.7383241\ttotal: 8m 25s\tremaining: 3m 43s\n",
      "1387:\tlearn: 0.7381012\ttotal: 8m 26s\tremaining: 3m 43s\n",
      "1388:\tlearn: 0.7378792\ttotal: 8m 26s\tremaining: 3m 42s\n",
      "1389:\tlearn: 0.7376695\ttotal: 8m 27s\tremaining: 3m 42s\n",
      "1390:\tlearn: 0.7374773\ttotal: 8m 27s\tremaining: 3m 42s\n",
      "1391:\tlearn: 0.7374131\ttotal: 8m 27s\tremaining: 3m 41s\n",
      "1392:\tlearn: 0.7373196\ttotal: 8m 28s\tremaining: 3m 41s\n",
      "1393:\tlearn: 0.7371019\ttotal: 8m 28s\tremaining: 3m 41s\n",
      "1394:\tlearn: 0.7369097\ttotal: 8m 29s\tremaining: 3m 40s\n",
      "1395:\tlearn: 0.7366484\ttotal: 8m 29s\tremaining: 3m 40s\n",
      "1396:\tlearn: 0.7365907\ttotal: 8m 30s\tremaining: 3m 40s\n",
      "1397:\tlearn: 0.7364990\ttotal: 8m 30s\tremaining: 3m 39s\n",
      "1398:\tlearn: 0.7362284\ttotal: 8m 30s\tremaining: 3m 39s\n",
      "1399:\tlearn: 0.7359744\ttotal: 8m 31s\tremaining: 3m 39s\n",
      "1400:\tlearn: 0.7357491\ttotal: 8m 32s\tremaining: 3m 38s\n",
      "1401:\tlearn: 0.7355616\ttotal: 8m 32s\tremaining: 3m 38s\n",
      "1402:\tlearn: 0.7353425\ttotal: 8m 33s\tremaining: 3m 38s\n",
      "1403:\tlearn: 0.7351404\ttotal: 8m 33s\tremaining: 3m 38s\n",
      "1404:\tlearn: 0.7350011\ttotal: 8m 34s\tremaining: 3m 37s\n",
      "1405:\tlearn: 0.7347865\ttotal: 8m 34s\tremaining: 3m 37s\n",
      "1406:\tlearn: 0.7346296\ttotal: 8m 35s\tremaining: 3m 37s\n",
      "1407:\tlearn: 0.7345638\ttotal: 8m 35s\tremaining: 3m 36s\n",
      "1408:\tlearn: 0.7343260\ttotal: 8m 35s\tremaining: 3m 36s\n",
      "1409:\tlearn: 0.7340820\ttotal: 8m 36s\tremaining: 3m 36s\n",
      "1410:\tlearn: 0.7338327\ttotal: 8m 36s\tremaining: 3m 35s\n",
      "1411:\tlearn: 0.7336280\ttotal: 8m 37s\tremaining: 3m 35s\n",
      "1412:\tlearn: 0.7333484\ttotal: 8m 38s\tremaining: 3m 35s\n",
      "1413:\tlearn: 0.7332612\ttotal: 8m 38s\tremaining: 3m 34s\n",
      "1414:\tlearn: 0.7330206\ttotal: 8m 38s\tremaining: 3m 34s\n",
      "1415:\tlearn: 0.7328506\ttotal: 8m 39s\tremaining: 3m 34s\n",
      "1416:\tlearn: 0.7327084\ttotal: 8m 39s\tremaining: 3m 33s\n",
      "1417:\tlearn: 0.7326634\ttotal: 8m 39s\tremaining: 3m 33s\n",
      "1418:\tlearn: 0.7324159\ttotal: 8m 40s\tremaining: 3m 33s\n",
      "1419:\tlearn: 0.7321544\ttotal: 8m 40s\tremaining: 3m 32s\n",
      "1420:\tlearn: 0.7319588\ttotal: 8m 41s\tremaining: 3m 32s\n",
      "1421:\tlearn: 0.7317524\ttotal: 8m 41s\tremaining: 3m 32s\n",
      "1422:\tlearn: 0.7316375\ttotal: 8m 42s\tremaining: 3m 31s\n",
      "1423:\tlearn: 0.7314019\ttotal: 8m 42s\tremaining: 3m 31s\n",
      "1424:\tlearn: 0.7311418\ttotal: 8m 43s\tremaining: 3m 31s\n",
      "1425:\tlearn: 0.7310834\ttotal: 8m 43s\tremaining: 3m 30s\n",
      "1426:\tlearn: 0.7308780\ttotal: 8m 44s\tremaining: 3m 30s\n",
      "1427:\tlearn: 0.7306675\ttotal: 8m 44s\tremaining: 3m 30s\n",
      "1428:\tlearn: 0.7304751\ttotal: 8m 45s\tremaining: 3m 29s\n",
      "1429:\tlearn: 0.7303594\ttotal: 8m 45s\tremaining: 3m 29s\n",
      "1430:\tlearn: 0.7301806\ttotal: 8m 46s\tremaining: 3m 29s\n",
      "1431:\tlearn: 0.7299853\ttotal: 8m 47s\tremaining: 3m 29s\n",
      "1432:\tlearn: 0.7298306\ttotal: 8m 47s\tremaining: 3m 28s\n",
      "1433:\tlearn: 0.7296279\ttotal: 8m 47s\tremaining: 3m 28s\n",
      "1434:\tlearn: 0.7293684\ttotal: 8m 48s\tremaining: 3m 28s\n",
      "1435:\tlearn: 0.7292100\ttotal: 8m 48s\tremaining: 3m 27s\n",
      "1436:\tlearn: 0.7290406\ttotal: 8m 49s\tremaining: 3m 27s\n",
      "1437:\tlearn: 0.7289014\ttotal: 8m 49s\tremaining: 3m 27s\n",
      "1438:\tlearn: 0.7288321\ttotal: 8m 49s\tremaining: 3m 26s\n",
      "1439:\tlearn: 0.7285750\ttotal: 8m 50s\tremaining: 3m 26s\n",
      "1440:\tlearn: 0.7283218\ttotal: 8m 51s\tremaining: 3m 26s\n",
      "1441:\tlearn: 0.7281571\ttotal: 8m 51s\tremaining: 3m 25s\n",
      "1442:\tlearn: 0.7280661\ttotal: 8m 52s\tremaining: 3m 25s\n",
      "1443:\tlearn: 0.7278939\ttotal: 8m 52s\tremaining: 3m 25s\n",
      "1444:\tlearn: 0.7276508\ttotal: 8m 53s\tremaining: 3m 24s\n",
      "1445:\tlearn: 0.7275260\ttotal: 8m 53s\tremaining: 3m 24s\n",
      "1446:\tlearn: 0.7274344\ttotal: 8m 53s\tremaining: 3m 23s\n",
      "1447:\tlearn: 0.7271928\ttotal: 8m 54s\tremaining: 3m 23s\n",
      "1448:\tlearn: 0.7271339\ttotal"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/04 09:03:44 ERROR Executor: Exception in task 0.0 in stage 79586.0 (TID 47295)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:03:44 WARN TaskSetManager: Lost task 0.0 in stage 79586.0 (TID 47295) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:03:44 ERROR TaskSetManager: Task 0 in stage 79586.0 failed 1 times; aborting job\n",
      "25/06/04 09:03:48 ERROR Executor: Exception in task 0.0 in stage 79735.0 (TID 47409)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:03:48 WARN TaskSetManager: Lost task 0.0 in stage 79735.0 (TID 47409) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:03:48 ERROR TaskSetManager: Task 0 in stage 79735.0 failed 1 times; aborting job\n",
      "25/06/04 09:03:52 ERROR Executor: Exception in task 0.0 in stage 80033.0 (TID 47599)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:03:52 WARN TaskSetManager: Lost task 0.0 in stage 80033.0 (TID 47599) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:03:52 ERROR TaskSetManager: Task 0 in stage 80033.0 failed 1 times; aborting job\n",
      "25/06/04 09:03:57 ERROR Executor: Exception in task 0.0 in stage 80443.0 (TID 47845)\n",
      "ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "25/06/04 09:03:57 WARN TaskSetManager: Lost task 0.0 in stage 80443.0 (TID 47845) (abd-vm.us-central1-c.c.project-big-data-461104.internal executor driver): ai.catboost.CatBoostError: An active CatBoost worker is already present in the current process\n",
      "\tat ai.catboost.spark.impl.CatBoostWorker.processPartition(Workers.scala:57)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10(Workers.scala:338)\n",
      "\tat ai.catboost.spark.impl.CatBoostWorkers$.$anonfun$apply$10$adapted(Workers.scala:327)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "\n",
      "25/06/04 09:03:57 ERROR TaskSetManager: Task 0 in stage 80443.0 failed 1 times; aborting job\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "# param_grid =(ParamGridBuilder()\n",
    "#             .addGrid(classifier.iterations, [2000,5000,10000])\n",
    "#             .addGrid(classifier.depth, [2,4,6,8,10])\n",
    "#             .addGrid(classifier.learningRate, [0.001,0.01, 0.05, 0.1])\n",
    "#             .addGrid(classifier.l2LeafReg, [1.0,3.0,5.0])\n",
    "#             .build())\n",
    "\n",
    "# tvs = TrainValidationSplit(\n",
    "#     estimator=classifier,\n",
    "#     estimatorParamMaps=param_grid,\n",
    "#     evaluator=evaluator,\n",
    "#     trainRatio=0.8,  \n",
    "#     parallelism=1   \n",
    "# )\n",
    "\n",
    "# tvs_model = tvs.fit(train_df)\n",
    "# best_model = tvs_model.bestModel\n",
    "# prediction = best_model.transform(test_df)\n",
    "# print(f'Model F1 = {evaluator.evaluate(prediction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4f8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
