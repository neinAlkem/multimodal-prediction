{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "758187a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, types\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from functools import reduce\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d733aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/Bagas/spark/spark-3.5.5-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/Bagas/.ivy2/cache\n",
      "The jars for the packages stored in: /home/Bagas/.ivy2/jars\n",
      "com.google.cloud.spark#spark-bigquery-with-dependencies_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-68cb7779-06db-46cd-8bb7-2034b6a16242;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.google.cloud.spark#spark-bigquery-with-dependencies_2.12;0.36.1 in central\n",
      ":: resolution report :: resolve 137ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.cloud.spark#spark-bigquery-with-dependencies_2.12;0.36.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-68cb7779-06db-46cd-8bb7-2034b6a16242\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/4ms)\n",
      "25/06/01 11:16:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('spark://localhost:7077') \\\n",
    "    .config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.36.1\") \\\n",
    "    .config(\"spark.jars\", \"https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop3-latest.jar\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.type\", \"SERVICE_ACCOUNT_JSON_KEYFILE\") \\\n",
    "    .config(\"spark.hadoop.fs.gs.project.id\", os.getenv('PROJECT_ID')) \\\n",
    "    .appName(\"fisiology_spark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87573f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'gs://project-abd/raw/class_wearable_data/'\n",
    "\n",
    "def sample_wearable(class_id, participant_id):\n",
    "    session_path = os.path.join(base_path, str(class_id), str(participant_id))\n",
    "    print(f'Processing : {session_path}..')\n",
    "    \n",
    "    sensor_map = {}\n",
    "    sensors = {'HR.csv': 'HR', 'TEMP.csv': 'TEMP'}\n",
    "    \n",
    "    for file_name, sensor_prefix in sensors.items():\n",
    "        file_path = os.path.join(session_path, file_name)\n",
    "        try:\n",
    "            df_sensor = pd.read_csv(file_path, header=None, names=[sensor_prefix, 'Time'])\n",
    "            \n",
    "            df_sensor.dropna(subset=['Time'], inplace=True)\n",
    "            df_sensor['Time'] = pd.to_datetime(df_sensor['Time'], errors='coerce')\n",
    "            df_sensor[sensor_prefix] = pd.to_numeric(df_sensor[sensor_prefix], errors='coerce')\n",
    "            df_sensor.dropna(subset=[sensor_prefix], inplace=True)\n",
    "            \n",
    "            if not df_sensor.empty:\n",
    "                df_sensor.set_index('Time', inplace=True)\n",
    "                sensor_map[sensor_prefix] = df_sensor[[sensor_prefix]]\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f'File not found: {file_path}')\n",
    "        except Exception as e:\n",
    "            print(f'Error processing {file_path}: {e}')\n",
    "    \n",
    "    if not sensor_map:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    all_features = []\n",
    "    for sensor_prefix, sensor_df in sensor_map.items():\n",
    "        if not sensor_df.empty and not sensor_df.isnull().all().all():\n",
    "            features = sensor_df.resample('5min').mean().reset_index()\n",
    "            features.columns = ['time', f'{sensor_prefix}_mean']\n",
    "            all_features.append(features.set_index('time'))\n",
    "\n",
    "    if not all_features:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    final_features_pd = pd.concat(all_features, axis=1).reset_index()\n",
    "    final_features_pd['time'] =   final_features_pd['time'].dt.strftime('%H:%M:%S')\n",
    "    final_features_pd['participant_id'] = participant_id\n",
    "    final_features_pd['class_id'] = class_id\n",
    "\n",
    "    return final_features_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a4bb714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : gs://project-abd/raw/class_wearable_data/1/1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25290/1930031351.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_sensor['Time'] = pd.to_datetime(df_sensor['Time'], errors='coerce')\n",
      "/tmp/ipykernel_25290/1930031351.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_sensor['Time'] = pd.to_datetime(df_sensor['Time'], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "HR_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TEMP_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "participant_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "class_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b74aca2d-ae0f-4d37-8c48-ed448b095cfb",
       "rows": [
        [
         "0",
         "09:20:00",
         "101.96850746268657",
         "18.796666666666667",
         "1",
         "1"
        ],
        [
         "1",
         "09:25:00",
         "112.20290000000001",
         "18.7992",
         "1",
         "1"
        ],
        [
         "2",
         "09:30:00",
         "110.07446666666665",
         "18.7822",
         "1",
         "1"
        ],
        [
         "3",
         "09:35:00",
         "124.70516666666667",
         "18.653233333333333",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>HR_mean</th>\n",
       "      <th>TEMP_mean</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09:20:00</td>\n",
       "      <td>101.968507</td>\n",
       "      <td>18.796667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09:25:00</td>\n",
       "      <td>112.202900</td>\n",
       "      <td>18.799200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>110.074467</td>\n",
       "      <td>18.782200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09:35:00</td>\n",
       "      <td>124.705167</td>\n",
       "      <td>18.653233</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time     HR_mean  TEMP_mean  participant_id  class_id\n",
       "0  09:20:00  101.968507  18.796667               1         1\n",
       "1  09:25:00  112.202900  18.799200               1         1\n",
       "2  09:30:00  110.074467  18.782200               1         1\n",
       "3  09:35:00  124.705167  18.653233               1         1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = sample_wearable(1, 1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f60c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'gs://project-abd/raw/class_wearable_data/'\n",
    "\n",
    "schema = types.StructType([\n",
    "    types.StructField('value', types.FloatType(), True),\n",
    "    types.StructField('Time', types.TimestampType(), True)\n",
    "])\n",
    "\n",
    "hr = spark.read.schema(schema).csv(base_path + '/1/*/HR.csv')\n",
    "temp = spark.read.schema(schema).csv(base_path + '/1/*/TEMP.csv')\n",
    "eda = spark.read.schema(schema).csv(base_path + '/1/*/EDA.csv')\n",
    "ibi = spark.read.schema(schema).csv(base_path + '/1/*/IBI.csv')\n",
    "bvp = spark.read.schema(schema).csv(base_path + '/1/*/BVP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94a2aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(df):\n",
    "    df = df.withColumn('class_id', F.regexp_extract(F.input_file_name(),r'class_wearable_data/(\\d+)/',1).cast('int'))\n",
    "    df = df.withColumn('participant_id', F.regexp_extract(F.input_file_name(),r'class_wearable_data/\\d+/(\\d+)/',1).cast('int'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7460d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = extract_id(hr)\n",
    "temp = extract_id(temp)\n",
    "eda = extract_id(eda)\n",
    "ibi = extract_id(ibi)\n",
    "bvp = extract_id(bvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85e9a8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------+--------------+\n",
      "|value|               Time|class_id|participant_id|\n",
      "+-----+-------------------+--------+--------------+\n",
      "| NULL|               NULL|       1|            13|\n",
      "| 52.0|2025-06-01 09:22:39|       1|            13|\n",
      "| 52.0|2025-06-01 09:22:40|       1|            13|\n",
      "|53.33|2025-06-01 09:22:41|       1|            13|\n",
      "| 60.0|2025-06-01 09:22:42|       1|            13|\n",
      "+-----+-------------------+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33520f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(df):\n",
    "    return df.withColumn('time_format',\n",
    "                         F.date_format('Time','HH:mm:ss')).drop('Time')\n",
    "\n",
    "hr_time = format_time(hr)\n",
    "temp_time = format_time(temp)\n",
    "eda_time = format_time(eda)\n",
    "ibi_time = format_time(ibi)\n",
    "bvp_time = format_time(bvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6379785f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------+-----------+\n",
      "|value|class_id|participant_id|time_format|\n",
      "+-----+--------+--------------+-----------+\n",
      "| NULL|       1|            13|       NULL|\n",
      "| 52.0|       1|            13|   09:22:39|\n",
      "| 52.0|       1|            13|   09:22:40|\n",
      "|53.33|       1|            13|   09:22:41|\n",
      "| 60.0|       1|            13|   09:22:42|\n",
      "+-----+--------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hr_time.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04074e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_sensor(df, alias):\n",
    "    return df.groupby('class_id', 'participant_id', F.window('time_format','5 minutes')\n",
    "                    ).agg(F.mean('value').alias(alias))\n",
    "\n",
    "hr_agg = agg_sensor(hr_time, 'hr_mean')\n",
    "temp_agg = agg_sensor(temp_time, 'temp_mean')\n",
    "eda_agg = agg_sensor(eda_time, 'eda_mean')\n",
    "ibi_agg = agg_sensor(ibi_time, 'ibi_mean')\n",
    "bvp_agg = agg_sensor(bvp_time, 'bvp_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a219d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_join = [hr_agg, temp_agg, eda_agg, ibi_agg, bvp_agg]\n",
    "df_join = reduce(lambda left,right:\n",
    "    left.join(right, on=\n",
    "              ['class_id',\n",
    "               'participant_id',\n",
    "               'window'], how='outer'),\n",
    "    df_to_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17508c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:======================================>                 (15 + 7) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------+------------------+------------------+--------------------+-------------------+--------------------+\n",
      "|class_id|participant_id|time_format|           hr_mean|         temp_mean|            eda_mean|           ibi_mean|            bvp_mean|\n",
      "+--------+--------------+-----------+------------------+------------------+--------------------+-------------------+--------------------+\n",
      "|       1|             1|   09:20:00|101.96850751051262| 18.79666699303521|0.001454626731881...|0.46877134839693707|0.005812729376985872|\n",
      "|       1|             1|   09:25:00|112.20290006001791| 18.79920024236043|3.533424931811168...|0.38022567331790924| 0.01111510058719432|\n",
      "|       1|             1|   09:30:00|110.07446683247885|18.782200450897218|3.661524929339066E-4| 0.3854343295097351|-0.01442968695181...|\n",
      "|       1|             1|   09:35:00| 124.7051665242513| 18.65323377609253|2.006899961270392E-4|0.38790275516668205|6.333332597084033E-4|\n",
      "|       1|             2|   09:20:00|103.59137417159917|18.808865675689482|5.271010639984822E-4|0.44533251225948334| 6.02816501739666E-4|\n",
      "|       1|             2|   09:25:00|106.70689994812011|18.898866551717123|                 0.0| 0.3984558383623759|-4.05206017409606...|\n",
      "|       1|             2|   09:30:00|126.61060017903645|18.918900063832602|                 0.0| 0.3828300014138222|4.312492553920795...|\n",
      "|       1|             2|   09:35:00|138.44159983317059|18.946800072987873|                 0.0| 0.5184895450418646|-6.39582534980339...|\n",
      "|       1|             3|   09:20:00|  94.1716801147461|19.449926178543656|0.017419001891674404| 0.5093982100486756| 0.09704513356102527|\n",
      "|       1|             3|   09:25:00|113.15723340352376| 19.47209987004598|0.015664255012137196| 0.5614096479756492| -0.0933947939867115|\n",
      "|       1|             3|   09:30:00|106.56929992675781|19.522300459543864|0.015685617499208698| 0.4577415918602663| 0.04964010517918117|\n",
      "|       1|             3|   09:35:00|   127.93443359375|19.564100290934245|0.015483820009976626|0.48439730818455035| 0.04184739725062779|\n",
      "|       1|             4|   09:20:00|106.63770500558321| 19.31196993047541|2.280568164265291...|  0.534507172888723|0.026483175063648643|\n",
      "|       1|             4|   09:25:00|115.44216649373372|19.441933244069418|                 0.0| 0.3593914955854416|-0.00554999904959...|\n",
      "|       1|             4|   09:30:00|107.88809997558593| 19.48913310368856|                 0.0| 0.4866292859826769|-0.00303958425938...|\n",
      "|       1|             4|   09:35:00|122.90936663309733|19.525433775583902|                 0.0|0.42189401388168335|-0.00194062479917...|\n",
      "|       1|             5|   09:20:00| 97.80948710645366|19.226220679095412|3.832775556783038E-4|0.45314559936523435|-0.03292815483245...|\n",
      "|       1|             5|   09:25:00|109.25509997049967| 19.32693353017171|                 0.0| 0.5469000140825907| 0.06340729170973645|\n",
      "|       1|             5|   09:30:00|107.90780001322429|19.396233361562093|                 0.0| 0.5833596587181091|-0.03066093168628...|\n",
      "|       1|             5|   09:35:00|120.48450019836426|19.453333326975503|                 0.0| 0.4236305554707845|-0.01445988515130...|\n",
      "+--------+--------------+-----------+------------------+------------------+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_df = df_join.withColumn('time', F.col('window').start).withColumn('time_format', F.date_format('time', 'HH:mm:ss')) \\\n",
    "    .select('class_id', 'participant_id', 'time_format','hr_mean', 'temp_mean', 'eda_mean', 'ibi_mean', 'bvp_mean'\n",
    ").orderBy('class_id', 'participant_id', 'time')\n",
    "\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22f06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
